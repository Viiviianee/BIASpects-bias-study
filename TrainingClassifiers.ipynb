{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp. Group 1 finished\n",
      "Exp. Group 2 finished\n",
      "Exp. Group 3 finished\n",
      "Exp. Group 4 finished\n",
      "Exp. Group 5 finished\n",
      "Exp. Group 6 finished\n",
      "Exp. Group 7 finished\n",
      "Exp. Group 8 finished\n",
      "Exp. Group 9 finished\n",
      "Exp. Group 10 finished\n",
      "Exp. Group 11 finished\n",
      "Exp. Group 12 finished\n",
      "Exp. Group 13 finished\n",
      "Exp. Group 14 finished\n",
      "Exp. Group 15 finished\n",
      "Exp. Group 16 finished\n",
      "Exp. Group 17 finished\n",
      "Exp. Group 18 finished\n",
      "Exp. Group 19 finished\n",
      "Exp. Group 20 finished\n",
      "Exp. Group 21 finished\n",
      "Exp. Group 22 finished\n",
      "Exp. Group 23 finished\n",
      "Exp. Group 24 finished\n",
      "Exp. Group 25 finished\n",
      "Exp. Group 26 finished\n",
      "Exp. Group 27 finished\n",
      "Exp. Group 28 finished\n",
      "Exp. Group 29 finished\n",
      "Exp. Group 30 finished\n",
      "Exp. Group 31 finished\n",
      "Exp. Group 32 finished\n",
      "Exp. Group 33 finished\n",
      "Exp. Group 34 finished\n",
      "Exp. Group 35 finished\n",
      "Exp. Group 36 finished\n",
      "Exp. Group 37 finished\n",
      "Exp. Group 38 finished\n",
      "Exp. Group 39 finished\n",
      "Exp. Group 40 finished\n",
      "Exp. Group 41 finished\n",
      "Exp. Group 42 finished\n",
      "Exp. Group 43 finished\n",
      "Exp. Group 44 finished\n",
      "Exp. Group 45 finished\n",
      "Exp. Group 46 finished\n",
      "Exp. Group 47 finished\n",
      "Exp. Group 48 finished\n",
      "Exp. Group 49 finished\n",
      "Exp. Group 50 finished\n",
      "Exp. Group 51 finished\n",
      "Exp. Group 52 finished\n",
      "Exp. Group 53 finished\n",
      "Exp. Group 54 finished\n",
      "Exp. Group 55 finished\n",
      "Exp. Group 56 finished\n",
      "Exp. Group 57 finished\n",
      "Exp. Group 58 finished\n",
      "Exp. Group 59 finished\n",
      "Exp. Group 60 finished\n",
      "Exp. Group 61 finished\n",
      "Exp. Group 62 finished\n",
      "Exp. Group 63 finished\n",
      "Exp. Group 64 finished\n",
      "Exp. Group 65 finished\n",
      "Exp. Group 66 finished\n",
      "Exp. Group 67 finished\n",
      "Exp. Group 68 finished\n",
      "Exp. Group 69 finished\n",
      "Exp. Group 70 finished\n",
      "Exp. Group 71 finished\n",
      "Exp. Group 72 finished\n",
      "Exp. Group 73 finished\n",
      "Exp. Group 74 finished\n",
      "Exp. Group 75 finished\n",
      "Exp. Group 76 finished\n",
      "Exp. Group 77 finished\n",
      "Exp. Group 78 finished\n",
      "Exp. Group 79 finished\n",
      "Exp. Group 80 finished\n",
      "Exp. Group 81 finished\n",
      "Exp. Group 82 finished\n",
      "Exp. Group 83 finished\n",
      "Exp. Group 84 finished\n",
      "Exp. Group 85 finished\n",
      "Exp. Group 86 finished\n",
      "Exp. Group 87 finished\n",
      "Exp. Group 88 finished\n",
      "Exp. Group 89 finished\n",
      "Exp. Group 90 finished\n",
      "Exp. Group 91 finished\n",
      "Exp. Group 92 finished\n",
      "Exp. Group 93 finished\n",
      "Exp. Group 94 finished\n",
      "Exp. Group 95 finished\n",
      "Exp. Group 96 finished\n",
      "Exp. Group 97 finished\n",
      "Exp. Group 98 finished\n",
      "Exp. Group 99 finished\n",
      "Exp. Group 100 finished\n",
      "Exp. Group 101 finished\n",
      "Exp. Group 102 finished\n",
      "Exp. Group 103 finished\n",
      "Exp. Group 104 finished\n",
      "Exp. Group 105 finished\n",
      "Exp. Group 106 finished\n",
      "Exp. Group 107 finished\n",
      "Exp. Group 108 finished\n",
      "Exp. Group 109 finished\n",
      "Exp. Group 110 finished\n",
      "Exp. Group 111 finished\n",
      "Exp. Group 112 finished\n",
      "Exp. Group 113 finished\n",
      "Exp. Group 114 finished\n",
      "Exp. Group 115 finished\n",
      "Exp. Group 116 finished\n",
      "Exp. Group 117 finished\n",
      "Exp. Group 118 finished\n",
      "Exp. Group 119 finished\n",
      "Exp. Group 120 finished\n",
      "Exp. Group 121 finished\n",
      "Exp. Group 122 finished\n",
      "Exp. Group 123 finished\n",
      "Exp. Group 124 finished\n",
      "Exp. Group 125 finished\n",
      "Exp. Group 126 finished\n",
      "Exp. Group 127 finished\n",
      "Exp. Group 128 finished\n",
      "Exp. Group 129 finished\n",
      "Exp. Group 130 finished\n",
      "Exp. Group 131 finished\n",
      "Exp. Group 132 finished\n",
      "Exp. Group 133 finished\n",
      "Exp. Group 134 finished\n",
      "Exp. Group 135 finished\n",
      "Exp. Group 136 finished\n",
      "Exp. Group 137 finished\n",
      "Exp. Group 138 finished\n",
      "Exp. Group 139 finished\n",
      "Exp. Group 140 finished\n",
      "Exp. Group 141 finished\n",
      "Exp. Group 142 finished\n",
      "Exp. Group 143 finished\n",
      "Exp. Group 144 finished\n",
      "Exp. Group 145 finished\n",
      "Exp. Group 146 finished\n",
      "Exp. Group 147 finished\n",
      "Exp. Group 148 finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from decimal import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results_df=pd.DataFrame(columns=['Exp. Group', '# Dataset', 'Seed','Ratio Men','Probability Men', 'Probability Women','Difference Probabilities','Confusion Matrix Men', 'Confusion Matrix Women'])\n",
    "for i in range(1,149):\n",
    "    df=pd.read_pickle('./group{}'.format(i))\n",
    "    df['Sex']=df['Sex'].map({'M':0,'F':1})\n",
    "    group=df.loc[:,'Exp. Group'].iloc[0]\n",
    "    ratio=df.loc[:,'Ratio Men'].iloc[0]\n",
    "    prob_men=df.loc[:,'Probability Men'].iloc[0]\n",
    "    prob_women=df.loc[:,'Probability Women'].iloc[0]\n",
    "    diff_prob=df.loc[:,'Difference Probabilities'].iloc[0]\n",
    "    for j in range(1,551):\n",
    "        df_sub=df[df['# Dataset']==j]\n",
    "        dataset=df_sub.loc[:,'# Dataset'].iloc[0]\n",
    "        seed=df_sub.loc[:,'Seed'].iloc[0]\n",
    "        df_sub=df_sub.drop(['Exp. Group', '# Dataset', 'Seed','Ratio Men','Probability Men', 'Probability Women','Difference Probabilities'], axis=1)\n",
    "        df_train=df_sub.iloc[0:1000]\n",
    "        df_test=df_sub.iloc[1000:2000]\n",
    "        scaler=StandardScaler()\n",
    "        X_train=scaler.fit_transform(df_train.drop('Label',axis=1))\n",
    "        X_test_m=scaler.transform(df_test.drop('Label',axis=1)[df_test['Sex']==0])\n",
    "        X_test_f=scaler.transform(df_test.drop('Label',axis=1)[df_test['Sex']==1])\n",
    "        y_train=df_train['Label']\n",
    "        y_test_m=df_test['Label'][df_test['Sex']==0]\n",
    "        y_test_f=df_test['Label'][df_test['Sex']==1]\n",
    "\n",
    "        SVM=SVC(kernel='linear',C=1)\n",
    "        SVM.fit(X_train,y_train)\n",
    "        y_predict_m=SVM.predict(X_test_m)\n",
    "        y_predict_f=SVM.predict(X_test_f)\n",
    "        matrix_m=np.zeros((2,2),int)\n",
    "        matrix_f=np.zeros((2,2),int)\n",
    "        for true_label,predicted_label in zip(y_test_m,y_predict_m):\n",
    "            if true_label ==0:\n",
    "                if predicted_label==0:\n",
    "                    matrix_m[0,0]+=1\n",
    "                else:\n",
    "                    matrix_m[0,1]+=1\n",
    "            else:\n",
    "                if predicted_label==0:\n",
    "                    matrix_m[1,0]+=1\n",
    "                else:\n",
    "                    matrix_m[1,1]+=1\n",
    "                    \n",
    "        for true_label,predicted_label in zip(y_test_f,y_predict_f):\n",
    "            if true_label ==0:\n",
    "                if predicted_label==0:\n",
    "                    matrix_f[0,0]+=1\n",
    "                else:\n",
    "                    matrix_f[0,1]+=1\n",
    "            else:\n",
    "                if predicted_label==0:\n",
    "                    matrix_f[1,0]+=1\n",
    "                else:\n",
    "                    matrix_f[1,1]+=1\n",
    "        \n",
    "        result=pd.DataFrame({'Exp. Group':group,'# Dataset':dataset,'Seed':seed,'Ratio Men':ratio,'Probability Men':prob_men,'Probability Women':prob_women,'Difference Probabilities':diff_prob,'Confusion Matrix Men':[matrix_m],'Confusion Matrix Women':[matrix_f]})\n",
    "        results_df=results_df.append(result,ignore_index=True)\n",
    "    print('Exp. Group {} finished'.format(i))\n",
    "\n",
    "results_df.to_pickle('./DF_Results_SVM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp. Group 1 finished\n",
      "Exp. Group 2 finished\n",
      "Exp. Group 3 finished\n",
      "Exp. Group 4 finished\n",
      "Exp. Group 5 finished\n",
      "Exp. Group 6 finished\n",
      "Exp. Group 7 finished\n",
      "Exp. Group 8 finished\n",
      "Exp. Group 9 finished\n",
      "Exp. Group 10 finished\n",
      "Exp. Group 11 finished\n",
      "Exp. Group 12 finished\n",
      "Exp. Group 13 finished\n",
      "Exp. Group 14 finished\n",
      "Exp. Group 15 finished\n",
      "Exp. Group 16 finished\n",
      "Exp. Group 17 finished\n",
      "Exp. Group 18 finished\n",
      "Exp. Group 19 finished\n",
      "Exp. Group 20 finished\n",
      "Exp. Group 21 finished\n",
      "Exp. Group 22 finished\n",
      "Exp. Group 23 finished\n",
      "Exp. Group 24 finished\n",
      "Exp. Group 25 finished\n",
      "Exp. Group 26 finished\n",
      "Exp. Group 27 finished\n",
      "Exp. Group 28 finished\n",
      "Exp. Group 29 finished\n",
      "Exp. Group 30 finished\n",
      "Exp. Group 31 finished\n",
      "Exp. Group 32 finished\n",
      "Exp. Group 33 finished\n",
      "Exp. Group 34 finished\n",
      "Exp. Group 35 finished\n",
      "Exp. Group 36 finished\n",
      "Exp. Group 37 finished\n",
      "Exp. Group 38 finished\n",
      "Exp. Group 39 finished\n",
      "Exp. Group 40 finished\n",
      "Exp. Group 41 finished\n",
      "Exp. Group 42 finished\n",
      "Exp. Group 43 finished\n",
      "Exp. Group 44 finished\n",
      "Exp. Group 45 finished\n",
      "Exp. Group 46 finished\n",
      "Exp. Group 47 finished\n",
      "Exp. Group 48 finished\n",
      "Exp. Group 49 finished\n",
      "Exp. Group 50 finished\n",
      "Exp. Group 51 finished\n",
      "Exp. Group 52 finished\n",
      "Exp. Group 53 finished\n",
      "Exp. Group 54 finished\n",
      "Exp. Group 55 finished\n",
      "Exp. Group 56 finished\n",
      "Exp. Group 57 finished\n",
      "Exp. Group 58 finished\n",
      "Exp. Group 59 finished\n",
      "Exp. Group 60 finished\n",
      "Exp. Group 61 finished\n",
      "Exp. Group 62 finished\n",
      "Exp. Group 63 finished\n",
      "Exp. Group 64 finished\n",
      "Exp. Group 65 finished\n",
      "Exp. Group 66 finished\n",
      "Exp. Group 67 finished\n",
      "Exp. Group 68 finished\n",
      "Exp. Group 69 finished\n",
      "Exp. Group 70 finished\n",
      "Exp. Group 71 finished\n",
      "Exp. Group 72 finished\n",
      "Exp. Group 73 finished\n",
      "Exp. Group 74 finished\n",
      "Exp. Group 75 finished\n",
      "Exp. Group 76 finished\n",
      "Exp. Group 77 finished\n",
      "Exp. Group 78 finished\n",
      "Exp. Group 79 finished\n",
      "Exp. Group 80 finished\n",
      "Exp. Group 81 finished\n",
      "Exp. Group 82 finished\n",
      "Exp. Group 83 finished\n",
      "Exp. Group 84 finished\n",
      "Exp. Group 85 finished\n",
      "Exp. Group 86 finished\n",
      "Exp. Group 87 finished\n",
      "Exp. Group 88 finished\n",
      "Exp. Group 89 finished\n",
      "Exp. Group 90 finished\n",
      "Exp. Group 91 finished\n",
      "Exp. Group 92 finished\n",
      "Exp. Group 93 finished\n",
      "Exp. Group 94 finished\n",
      "Exp. Group 95 finished\n",
      "Exp. Group 96 finished\n",
      "Exp. Group 97 finished\n",
      "Exp. Group 98 finished\n",
      "Exp. Group 99 finished\n",
      "Exp. Group 100 finished\n",
      "Exp. Group 101 finished\n",
      "Exp. Group 102 finished\n",
      "Exp. Group 103 finished\n",
      "Exp. Group 104 finished\n",
      "Exp. Group 105 finished\n",
      "Exp. Group 106 finished\n",
      "Exp. Group 107 finished\n",
      "Exp. Group 108 finished\n",
      "Exp. Group 109 finished\n",
      "Exp. Group 110 finished\n",
      "Exp. Group 111 finished\n",
      "Exp. Group 112 finished\n",
      "Exp. Group 113 finished\n",
      "Exp. Group 114 finished\n",
      "Exp. Group 115 finished\n",
      "Exp. Group 116 finished\n",
      "Exp. Group 117 finished\n",
      "Exp. Group 118 finished\n",
      "Exp. Group 119 finished\n",
      "Exp. Group 120 finished\n",
      "Exp. Group 121 finished\n",
      "Exp. Group 122 finished\n",
      "Exp. Group 123 finished\n",
      "Exp. Group 124 finished\n",
      "Exp. Group 125 finished\n",
      "Exp. Group 126 finished\n",
      "Exp. Group 127 finished\n",
      "Exp. Group 128 finished\n",
      "Exp. Group 129 finished\n",
      "Exp. Group 130 finished\n",
      "Exp. Group 131 finished\n",
      "Exp. Group 132 finished\n",
      "Exp. Group 133 finished\n",
      "Exp. Group 134 finished\n",
      "Exp. Group 135 finished\n",
      "Exp. Group 136 finished\n",
      "Exp. Group 137 finished\n",
      "Exp. Group 138 finished\n",
      "Exp. Group 139 finished\n",
      "Exp. Group 140 finished\n",
      "Exp. Group 141 finished\n",
      "Exp. Group 142 finished\n",
      "Exp. Group 143 finished\n",
      "Exp. Group 144 finished\n",
      "Exp. Group 145 finished\n",
      "Exp. Group 146 finished\n",
      "Exp. Group 147 finished\n",
      "Exp. Group 148 finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from decimal import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results_df=pd.DataFrame(columns=['Exp. Group', '# Dataset', 'Seed','Ratio Men','Probability Men', 'Probability Women','Difference Probabilities','Confusion Matrix Men', 'Confusion Matrix Women'])\n",
    "for i in range(1,149):\n",
    "    df=pd.read_pickle('./group{}'.format(i))\n",
    "    df['Sex']=df['Sex'].map({'M':0,'F':1})\n",
    "    group=df.loc[:,'Exp. Group'].iloc[0]\n",
    "    ratio=df.loc[:,'Ratio Men'].iloc[0]\n",
    "    prob_men=df.loc[:,'Probability Men'].iloc[0]\n",
    "    prob_women=df.loc[:,'Probability Women'].iloc[0]\n",
    "    diff_prob=df.loc[:,'Difference Probabilities'].iloc[0]\n",
    "    for j in range(1,551):\n",
    "        df_sub=df[df['# Dataset']==j]\n",
    "        dataset=df_sub.loc[:,'# Dataset'].iloc[0]\n",
    "        seed=df_sub.loc[:,'Seed'].iloc[0]\n",
    "        df_sub=df_sub.drop(['Exp. Group', '# Dataset', 'Seed','Ratio Men','Probability Men', 'Probability Women','Difference Probabilities'], axis=1)\n",
    "        df_train=df_sub.iloc[0:1000]\n",
    "        df_test=df_sub.iloc[1000:2000]\n",
    "        scaler=StandardScaler()\n",
    "        X_train=scaler.fit_transform(df_train.drop('Label',axis=1))\n",
    "        X_test_m=scaler.transform(df_test.drop('Label',axis=1)[df_test['Sex']==0])\n",
    "        X_test_f=scaler.transform(df_test.drop('Label',axis=1)[df_test['Sex']==1])\n",
    "        y_train=df_train['Label']\n",
    "        y_test_m=df_test['Label'][df_test['Sex']==0]\n",
    "        y_test_f=df_test['Label'][df_test['Sex']==1]\n",
    "\n",
    "        gnb = GaussianNB()\n",
    "        y_predict_m=gnb.fit(X_train, y_train).predict(X_test_m)\n",
    "        y_predict_f=gnb.fit(X_train, y_train).predict(X_test_f)\n",
    "        \n",
    "        matrix_m=np.zeros((2,2),int)\n",
    "        matrix_f=np.zeros((2,2),int)\n",
    "        for true_label,predicted_label in zip(y_test_m,y_predict_m):\n",
    "            if true_label ==0:\n",
    "                if predicted_label==0:\n",
    "                    matrix_m[0,0]+=1\n",
    "                else:\n",
    "                    matrix_m[0,1]+=1\n",
    "            else:\n",
    "                if predicted_label==0:\n",
    "                    matrix_m[1,0]+=1\n",
    "                else:\n",
    "                    matrix_m[1,1]+=1\n",
    "                    \n",
    "        for true_label,predicted_label in zip(y_test_f,y_predict_f):\n",
    "            if true_label ==0:\n",
    "                if predicted_label==0:\n",
    "                    matrix_f[0,0]+=1\n",
    "                else:\n",
    "                    matrix_f[0,1]+=1\n",
    "            else:\n",
    "                if predicted_label==0:\n",
    "                    matrix_f[1,0]+=1\n",
    "                else:\n",
    "                    matrix_f[1,1]+=1\n",
    "        \n",
    "        result=pd.DataFrame({'Exp. Group':group,'# Dataset':dataset,'Seed':seed,'Ratio Men':ratio,'Probability Men':prob_men,'Probability Women':prob_women,'Difference Probabilities':diff_prob,'Confusion Matrix Men':[matrix_m],'Confusion Matrix Women':[matrix_f]})\n",
    "        results_df=results_df.append(result,ignore_index=True)\n",
    "    print('Exp. Group {} finished'.format(i))\n",
    "\n",
    "results_df.to_pickle('./DF_Results_NB.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c8c035a43042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdf_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_sub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mX_test_m\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mX_test_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oefel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oefel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oefel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    732\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples_seen_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m                     _incremental_mean_and_var(X, self.mean_, self.var_,\n\u001b[1;32m--> 734\u001b[1;33m                                               self.n_samples_seen_)\n\u001b[0m\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         \u001b[1;31m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oefel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36m_incremental_mean_and_var\u001b[1;34m(X, last_mean, last_variance, last_sample_count)\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mupdated_variance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[0mnew_unnormalized_variance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnew_sample_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m         \u001b[0mlast_unnormalized_variance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_variance\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlast_sample_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oefel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36mnanvar\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m   1474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m     \"\"\"\n\u001b[1;32m-> 1476\u001b[1;33m     \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_replace_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1477\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         return np.var(arr, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "\u001b[1;32mc:\\users\\oefel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36m_replace_nan\u001b[1;34m(a, val)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from decimal import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results_df=pd.DataFrame(columns=['Exp. Group', '# Dataset', 'Seed','Ratio Men','Probability Men', 'Probability Women','Difference Probabilities','Confusion Matrix Men', 'Confusion Matrix Women'])\n",
    "for i in range(1,149):\n",
    "    df=pd.read_pickle('C:/Users/oefel/Documents/Datasets/group{}'.format(i))\n",
    "    df['Sex']=df['Sex'].map({'M':0,'F':1})\n",
    "    group=df.loc[:,'Exp. Group'].iloc[0]\n",
    "    ratio=df.loc[:,'Ratio Men'].iloc[0]\n",
    "    prob_men=df.loc[:,'Probability Men'].iloc[0]\n",
    "    prob_women=df.loc[:,'Probability Women'].iloc[0]\n",
    "    diff_prob=df.loc[:,'Difference Probabilities'].iloc[0]\n",
    "    for j in range(1,551):\n",
    "        df_sub=df[df['# Dataset']==j]\n",
    "        dataset=df_sub.loc[:,'# Dataset'].iloc[0]\n",
    "        seed=df_sub.loc[:,'Seed'].iloc[0]\n",
    "        df_sub=df_sub.drop(['Exp. Group', '# Dataset', 'Seed','Ratio Men','Probability Men', 'Probability Women','Difference Probabilities'], axis=1)\n",
    "        df_train=df_sub.iloc[0:1000]\n",
    "        df_test=df_sub.iloc[1000:2000]\n",
    "        scaler=StandardScaler()\n",
    "        X_train=scaler.fit_transform(df_train.drop('Label',axis=1))\n",
    "        X_test_m=scaler.transform(df_test.drop('Label',axis=1)[df_test['Sex']==0])\n",
    "        X_test_f=scaler.transform(df_test.drop('Label',axis=1)[df_test['Sex']==1])\n",
    "        y_train=df_train['Label']\n",
    "        y_test_m=df_test['Label'][df_test['Sex']==0]\n",
    "        y_test_f=df_test['Label'][df_test['Sex']==1]\n",
    "\n",
    "        clf = DecisionTreeClassifier(min_samples_split=0.05, min_samples_leaf=0.01)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        y_predict_m=clf.predict(X_test_m)\n",
    "        y_predict_f=clf.predict(X_test_f)\n",
    "\n",
    "        matrix_m=np.zeros((2,2),int)\n",
    "        matrix_f=np.zeros((2,2),int)\n",
    "        for true_label,predicted_label in zip(y_test_m,y_predict_m):\n",
    "            if true_label ==0:\n",
    "                if predicted_label==0:\n",
    "                    matrix_m[0,0]+=1\n",
    "                else:\n",
    "                    matrix_m[0,1]+=1\n",
    "            else:\n",
    "                if predicted_label==0:\n",
    "                    matrix_m[1,0]+=1\n",
    "                else:\n",
    "                    matrix_m[1,1]+=1\n",
    "                    \n",
    "        for true_label,predicted_label in zip(y_test_f,y_predict_f):\n",
    "            if true_label ==0:\n",
    "                if predicted_label==0:\n",
    "                    matrix_f[0,0]+=1\n",
    "                else:\n",
    "                    matrix_f[0,1]+=1\n",
    "            else:\n",
    "                if predicted_label==0:\n",
    "                    matrix_f[1,0]+=1\n",
    "                else:\n",
    "                    matrix_f[1,1]+=1\n",
    "        \n",
    "        result=pd.DataFrame({'Exp. Group':group,'# Dataset':dataset,'Seed':seed,'Ratio Men':ratio,'Probability Men':prob_men,'Probability Women':prob_women,'Difference Probabilities':diff_prob,'Confusion Matrix Men':[matrix_m],'Confusion Matrix Women':[matrix_f]})\n",
    "        results_df=results_df.append(result,ignore_index=True)\n",
    "    \n",
    "    print('Exp. Group {} finished'.format(i))\n",
    "\n",
    "results_df.to_pickle('./DF_Results_tree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948\n",
      "0.936\n",
      "0.928\n",
      "0.946\n",
      "0.93\n",
      "0.952\n",
      "0.97\n",
      "0.95\n",
      "0.95\n",
      "0.97\n",
      "0.958\n",
      "0.972\n",
      "0.954\n",
      "0.95\n",
      "0.962\n",
      "0.958\n",
      "0.952\n",
      "0.942\n",
      "0.956\n",
      "0.962\n",
      "0.954\n",
      "0.948\n",
      "0.952\n",
      "0.954\n",
      "0.952\n",
      "0.97\n",
      "0.968\n",
      "0.948\n",
      "0.94\n",
      "0.954\n",
      "0.96\n",
      "0.958\n",
      "0.948\n",
      "0.954\n",
      "0.95\n",
      "0.946\n",
      "0.966\n",
      "0.95\n",
      "0.944\n",
      "0.954\n",
      "0.96\n",
      "0.962\n",
      "0.95\n",
      "0.942\n",
      "0.95\n",
      "0.956\n",
      "0.936\n",
      "0.932\n",
      "0.95\n",
      "0.942\n",
      "0.942\n",
      "0.952\n",
      "0.942\n",
      "0.952\n",
      "0.96\n",
      "0.954\n",
      "0.948\n",
      "0.954\n",
      "0.95\n",
      "0.97\n",
      "0.936\n",
      "0.958\n",
      "0.968\n",
      "0.948\n",
      "0.958\n",
      "0.954\n",
      "0.944\n",
      "0.934\n",
      "0.966\n",
      "0.952\n",
      "0.954\n",
      "0.942\n",
      "0.954\n",
      "0.948\n",
      "0.946\n",
      "0.952\n",
      "0.948\n",
      "0.95\n",
      "0.914\n",
      "0.944\n",
      "0.972\n",
      "0.956\n",
      "0.95\n",
      "0.964\n",
      "0.958\n",
      "0.962\n",
      "0.946\n",
      "0.946\n",
      "0.944\n",
      "0.946\n",
      "0.948\n",
      "0.934\n",
      "0.948\n",
      "0.936\n",
      "0.928\n",
      "0.946\n",
      "0.93\n",
      "0.048\n",
      "0.97\n",
      "0.95\n",
      "0.95\n",
      "0.97\n",
      "0.958\n",
      "0.972\n",
      "0.954\n",
      "0.95\n",
      "0.962\n",
      "0.958\n",
      "0.952\n",
      "0.942\n",
      "0.956\n",
      "0.962\n",
      "0.954\n",
      "0.948\n",
      "0.952\n",
      "0.954\n",
      "0.952\n",
      "0.97\n",
      "0.968\n",
      "0.948\n",
      "0.942\n",
      "0.954\n",
      "0.96\n",
      "0.958\n",
      "0.948\n",
      "0.954\n",
      "0.95\n",
      "0.946\n",
      "0.966\n",
      "0.956\n",
      "0.944\n",
      "0.954\n",
      "0.96\n",
      "0.962\n",
      "0.95\n",
      "0.942\n",
      "0.95\n",
      "0.956\n",
      "0.936\n",
      "0.932\n",
      "0.95\n",
      "0.942\n",
      "0.942\n",
      "0.952\n",
      "0.942\n",
      "0.952\n",
      "0.96\n",
      "0.954\n",
      "0.948\n",
      "0.954\n",
      "0.95\n",
      "0.03\n",
      "0.936\n",
      "0.958\n",
      "0.968\n",
      "0.052\n",
      "0.958\n",
      "0.954\n",
      "0.056\n",
      "0.066\n",
      "0.966\n",
      "0.952\n",
      "0.954\n",
      "0.942\n",
      "0.954\n",
      "0.948\n",
      "0.054\n",
      "0.952\n",
      "0.052\n",
      "0.95\n",
      "0.086\n",
      "0.944\n",
      "0.972\n",
      "0.956\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1c3f50fa0c36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mdiff_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Difference Probabilities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m551\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mdf_sub\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'# Dataset'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_sub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'# Dataset'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_sub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Seed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oefel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1767\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1768\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[1;32mc:\\users\\oefel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1649\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1650\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0minvalid_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from decimal import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results_df=pd.DataFrame(columns=['Exp. Group', '# Dataset', 'Seed','Ratio Men','Probability Men', 'Probability Women','Difference Probabilities','Confusion Matrix Men', 'Confusion Matrix Women'])\n",
    "for i in range(1,149):\n",
    "    df=pd.read_pickle('C:/Users/oefel/Documents/Datasets/group{}'.format(i))\n",
    "    df['Sex']=df['Sex'].map({'M':0,'F':1})\n",
    "    group=df.loc[:,'Exp. Group'].iloc[0]\n",
    "    ratio=df.loc[:,'Ratio Men'].iloc[0]\n",
    "    prob_men=df.loc[:,'Probability Men'].iloc[0]\n",
    "    prob_women=df.loc[:,'Probability Women'].iloc[0]\n",
    "    diff_prob=df.loc[:,'Difference Probabilities'].iloc[0]\n",
    "    for j in range(1,551):\n",
    "        df_sub=df[df['# Dataset']==j]\n",
    "        dataset=df_sub.loc[:,'# Dataset'].iloc[0]\n",
    "        seed=df_sub.loc[:,'Seed'].iloc[0]\n",
    "        df_sub=df_sub.drop(['Exp. Group', '# Dataset', 'Seed','Ratio Men','Probability Men', 'Probability Women','Difference Probabilities'], axis=1)\n",
    "        df_train=df_sub.iloc[0:1000]\n",
    "        df_train=df_sub.sample(frac=1)\n",
    "        df_test=df_sub.iloc[1000:2000]\n",
    "        scaler=MinMaxScaler()\n",
    "        X_train=scaler.fit_transform(df_train.drop('Label',axis=1))\n",
    "        X_test_m=scaler.transform(df_test.drop('Label',axis=1)[df_test['Sex']==0])\n",
    "        X_test_f=scaler.transform(df_test.drop('Label',axis=1)[df_test['Sex']==1])\n",
    "        y_train=df_train['Label']\n",
    "        y_test_m=df_test['Label'][df_test['Sex']==0]\n",
    "        y_test_f=df_test['Label'][df_test['Sex']==1]\n",
    "\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(10,5), activation='logistic', solver='adam', alpha=0.01, early_stopping=True,\n",
    "                           validation_fraction=0.1,max_iter=2000, learning_rate='invscaling', n_iter_no_change=50)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        y_predict_m=clf.predict(X_test_m)\n",
    "        y_predict_f=clf.predict(X_test_f)\n",
    "        \n",
    "        print(clf.score(X_test_m,y_test_m))\n",
    "        matrix_m=np.zeros((2,2),int)\n",
    "        matrix_f=np.zeros((2,2),int)\n",
    "        for true_label,predicted_label in zip(y_test_m,y_predict_m):\n",
    "            if true_label ==0:\n",
    "                if predicted_label==0:\n",
    "                    matrix_m[0,0]+=1\n",
    "                else:\n",
    "                    matrix_m[0,1]+=1\n",
    "            else:\n",
    "                if predicted_label==0:\n",
    "                    matrix_m[1,0]+=1\n",
    "                else:\n",
    "                    matrix_m[1,1]+=1\n",
    "                    \n",
    "        for true_label,predicted_label in zip(y_test_f,y_predict_f):\n",
    "            if true_label ==0:\n",
    "                if predicted_label==0:\n",
    "                    matrix_f[0,0]+=1\n",
    "                else:\n",
    "                    matrix_f[0,1]+=1\n",
    "            else:\n",
    "                if predicted_label==0:\n",
    "                    matrix_f[1,0]+=1\n",
    "                else:\n",
    "                    matrix_f[1,1]+=1\n",
    "        \n",
    "        result=pd.DataFrame({'Exp. Group':group,'# Dataset':dataset,'Seed':seed,'Ratio Men':ratio,'Probability Men':prob_men,'Probability Women':prob_women,'Difference Probabilities':diff_prob,'Confusion Matrix Men':[matrix_m],'Confusion Matrix Women':[matrix_f]})\n",
    "        results_df=results_df.append(result,ignore_index=True)\n",
    "    \n",
    "    print('Exp. Group {} finished'.format(i))\n",
    "\n",
    "results_df.to_pickle('./DF_Results_NN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
