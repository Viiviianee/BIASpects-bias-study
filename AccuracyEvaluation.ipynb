{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "#import plotly.express as px\n",
    "#import ipywidgets as widgets\n",
    "#from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "#import statsmodels.stats\n",
    "#from statsmodels.stats import *\n",
    "#import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DF_Results_SVM.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "with open('DF_Results_SVM_noSex.pkl', 'rb') as f:\n",
    "    data_nosex = pickle.load(f)\n",
    "    \n",
    "with open('DF_Results_SVM_noSex_noHeight.pkl', 'rb') as f:\n",
    "    data_nosexinf = pickle.load(f)\n",
    "    \n",
    "with open('DF_Results_NB.pkl','rb') as f:\n",
    "    data_nb=pickle.load(f)\n",
    "\n",
    "with open('DF_Results_tree.pkl','rb') as f:\n",
    "    data_tree=pickle.load(f)\n",
    "    \n",
    "with open('DF_Results_SVM_CLEAN.pkl', 'rb') as f:\n",
    "    data_clean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Accuracy and Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "accuracy_men=[]\n",
    "accuracy_women=[]\n",
    "accuracy_bias=[]\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    acc_men=(data['Confusion Matrix Men'][i][0,0]+data['Confusion Matrix Men'][i][1,1])/(1000*data['Ratio Men'][i])\n",
    "    accuracy_men.append(float(acc_men))\n",
    "    acc_women=(data['Confusion Matrix Women'][i][0,0]+data['Confusion Matrix Women'][i][1,1])/(1000*(1-data['Ratio Men'][i]))\n",
    "    accuracy_women.append(float(acc_women))\n",
    "    acc_bias=acc_men-acc_women\n",
    "    accuracy_bias.append(float(acc_bias))\n",
    "    acc=(data['Confusion Matrix Men'][i][0,0]+data['Confusion Matrix Men'][i][1,1]+data['Confusion Matrix Women'][i][0,0]+data['Confusion Matrix Women'][i][1,1])/1000\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "data['Accuracy Men']=accuracy_men\n",
    "data[\"Accuracy Women\"]=accuracy_women\n",
    "data['Bias']=accuracy_bias\n",
    "data['Accuracy']=accuracy\n",
    "\n",
    "data['Absolute Bias']=data['Bias'].abs()\n",
    "data['Absolute Difference']=data['Difference Probabilities'].abs()\n",
    "data['Informativeness Men']=data['Probability Men'].astype(float)-([0.5]*len(data))\n",
    "data['Informativeness Men']=data['Informativeness Men'].abs().round(2)\n",
    "data['Informativeness Women']=data['Probability Women'].astype(float)-([0.5]*len(data))\n",
    "data['Informativeness Women']=data['Informativeness Women'].abs().round(2)\n",
    "data['Infomativeness_Difference']=data['Informativeness Men']-data['Informativeness Women']\n",
    "data['Infomativeness_Difference']=data['Infomativeness_Difference'].round(2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - ALL DATA CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "accuracy_men=[]\n",
    "accuracy_women=[]\n",
    "accuracy_bias=[]\n",
    "\n",
    "for i in range(0,len(data_clean)):\n",
    "    acc_men=(data_clean['Confusion Matrix Men'][i][0,0]+data_clean['Confusion Matrix Men'][i][1,1])/(1000*data_clean['Ratio Men'][i])\n",
    "    accuracy_men.append(float(acc_men))\n",
    "    acc_women=(data_clean['Confusion Matrix Women'][i][0,0]+data_clean['Confusion Matrix Women'][i][1,1])/(1000*(1-data_clean['Ratio Men'][i]))\n",
    "    accuracy_women.append(float(acc_women))\n",
    "    acc_bias=acc_men-acc_women\n",
    "    accuracy_bias.append(float(acc_bias))\n",
    "    acc=(data_clean['Confusion Matrix Men'][i][0,0]+data_clean['Confusion Matrix Men'][i][1,1]+data_clean['Confusion Matrix Women'][i][0,0]+data_clean['Confusion Matrix Women'][i][1,1])/1000\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "data_clean['Accuracy Men']=accuracy_men\n",
    "data_clean[\"Accuracy Women\"]=accuracy_women\n",
    "data_clean['Bias']=accuracy_bias\n",
    "data_clean['Accuracy']=accuracy\n",
    "\n",
    "data_clean['Absolute Bias']=data_clean['Bias'].abs()\n",
    "data_clean['Absolute Difference']=data_clean['Difference Probabilities'].abs()\n",
    "data_clean['Informativeness Men']=data_clean['Probability Men'].astype(float)-([0.5]*len(data_clean))\n",
    "data_clean['Informativeness Men']=data_clean['Informativeness Men'].abs().round(2)\n",
    "data_clean['Informativeness Women']=data_clean['Probability Women'].astype(float)-([0.5]*len(data_clean))\n",
    "data_clean['Informativeness Women']=data_clean['Informativeness Women'].abs().round(2)\n",
    "data_clean['Infomativeness_Difference']=data_clean['Informativeness Men']-data_clean['Informativeness Women']\n",
    "data_clean['Infomativeness_Difference']=data_clean['Infomativeness_Difference'].round(2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - WITHOUT ANY GENDER INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "accuracy_men=[]\n",
    "accuracy_women=[]\n",
    "accuracy_bias=[]\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    acc_men=(data_nosexinf['Confusion Matrix Men'][i][0,0]+data_nosexinf['Confusion Matrix Men'][i][1,1])/(1000*data_nosexinf['Ratio Men'][i])\n",
    "    accuracy_men.append(float(acc_men))\n",
    "    acc_women=(data_nosexinf['Confusion Matrix Women'][i][0,0]+data_nosexinf['Confusion Matrix Women'][i][1,1])/(1000*(1-data_nosexinf['Ratio Men'][i]))\n",
    "    accuracy_women.append(float(acc_women))\n",
    "    acc_bias=acc_men-acc_women\n",
    "    accuracy_bias.append(float(acc_bias))\n",
    "    acc=(data_nosexinf['Confusion Matrix Men'][i][0,0]+data_nosexinf['Confusion Matrix Men'][i][1,1]+data_nosexinf['Confusion Matrix Women'][i][0,0]+data_nosexinf['Confusion Matrix Women'][i][1,1])/1000\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "data_nosexinf['Accuracy Men']=accuracy_men\n",
    "data_nosexinf[\"Accuracy Women\"]=accuracy_women\n",
    "data_nosexinf['Bias']=accuracy_bias\n",
    "data_nosexinf['Accuracy']=accuracy\n",
    "\n",
    "data_nosexinf['Absolute Bias']=data_nosexinf['Bias'].abs()\n",
    "data_nosexinf['Absolute Difference']=data_nosexinf['Difference Probabilities'].abs()\n",
    "data_nosexinf['Informativeness Men']=data_nosexinf['Probability Men'].astype(float)-([0.5]*len(data_nosexinf))\n",
    "data_nosexinf['Informativeness Men']=data_nosexinf['Informativeness Men'].abs().round(2)\n",
    "data_nosexinf['Informativeness Women']=data_nosexinf['Probability Women'].astype(float)-([0.5]*len(data_nosexinf))\n",
    "data_nosexinf['Informativeness Women']=data_nosexinf['Informativeness Women'].abs().round(2)\n",
    "data_nosexinf['Infomativeness_Difference']=data_nosexinf['Informativeness Men']-data_nosexinf['Informativeness Women']\n",
    "data_nosexinf['Infomativeness_Difference']=data_nosexinf['Infomativeness_Difference'].round(2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - WITHOUT GENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "accuracy_men=[]\n",
    "accuracy_women=[]\n",
    "accuracy_bias=[]\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    acc_men=(data_nosex['Confusion Matrix Men'][i][0,0]+data_nosex['Confusion Matrix Men'][i][1,1])/(1000*data_nosex['Ratio Men'][i])\n",
    "    accuracy_men.append(float(acc_men))\n",
    "    acc_women=(data_nosex['Confusion Matrix Women'][i][0,0]+data_nosex['Confusion Matrix Women'][i][1,1])/(1000*(1-data_nosex['Ratio Men'][i]))\n",
    "    accuracy_women.append(float(acc_women))\n",
    "    acc_bias=acc_men-acc_women\n",
    "    accuracy_bias.append(float(acc_bias))\n",
    "    acc=(data_nosex['Confusion Matrix Men'][i][0,0]+data_nosex['Confusion Matrix Men'][i][1,1]+data_nosex['Confusion Matrix Women'][i][0,0]+data_nosex['Confusion Matrix Women'][i][1,1])/1000\n",
    "    accuracy.append(acc)\n",
    "\n",
    "data_nosex['Accuracy Men']=accuracy_men\n",
    "data_nosex[\"Accuracy Women\"]=accuracy_women\n",
    "data_nosex['Bias']=accuracy_bias\n",
    "data_nosex['Accuracy']=accuracy\n",
    "\n",
    "data_nosex['Absolute Bias']=data_nosex['Bias'].abs()\n",
    "data_nosex['Absolute Difference']=data_nosex['Difference Probabilities'].abs()\n",
    "data_nosex['Informativeness Men']=data_nosex['Probability Men'].astype(float)-([0.5]*len(data_nosex))\n",
    "data_nosex['Informativeness Men']=data_nosex['Informativeness Men'].abs().round(2)\n",
    "data_nosex['Informativeness Women']=data_nosex['Probability Women'].astype(float)-([0.5]*len(data_nosex))\n",
    "data_nosex['Informativeness Women']=data_nosex['Informativeness Women'].abs().round(2)\n",
    "data_nosex['Infomativeness_Difference']=data_nosex['Informativeness Men']-data_nosex['Informativeness Women']\n",
    "data_nosex['Infomativeness_Difference']=data_nosex['Infomativeness_Difference'].round(2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES - ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "accuracy_men_nb=[]\n",
    "accuracy_women_nb=[]\n",
    "accuracy_bias_nb=[]\n",
    "\n",
    "for i in range(0,len(data_nb)):\n",
    "    acc_men=(data_nb['Confusion Matrix Men'][i][0,0]+data_nb['Confusion Matrix Men'][i][1,1])/(1000*data_nb['Ratio Men'][i])\n",
    "    accuracy_men_nb.append(float(acc_men))\n",
    "    acc_women=(data_nb['Confusion Matrix Women'][i][0,0]+data_nb['Confusion Matrix Women'][i][1,1])/(1000*(1-data_nb['Ratio Men'][i]))\n",
    "    accuracy_women_nb.append(float(acc_women))\n",
    "    acc_bias=acc_men-acc_women\n",
    "    accuracy_bias_nb.append(float(acc_bias))\n",
    "    acc=(data_nb['Confusion Matrix Men'][i][0,0]+data_nb['Confusion Matrix Men'][i][1,1]+data_nb['Confusion Matrix Women'][i][0,0]+data_nb['Confusion Matrix Women'][i][1,1])/1000\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "\n",
    "data_nb['Accuracy Men']=accuracy_men_nb\n",
    "data_nb[\"Accuracy Women\"]=accuracy_women_nb\n",
    "data_nb['Bias']=accuracy_bias_nb\n",
    "data_nb['Accuracy']=accuracy\n",
    "\n",
    "data_nb['Absolute Bias']=data_nb['Bias'].abs()\n",
    "data_nb['Absolute Difference']=data_nb['Difference Probabilities'].abs()\n",
    "data_nb['Informativeness Men']=data_nb['Probability Men'].astype(float)-([0.5]*len(data))\n",
    "data_nb['Informativeness Men']=data_nb['Informativeness Men'].abs().round(2)\n",
    "data_nb['Informativeness Women']=data_nb['Probability Women'].astype(float)-([0.5]*len(data))\n",
    "data_nb['Informativeness Women']=data_nb['Informativeness Women'].abs().round(2)\n",
    "data_nb['Infomativeness_Difference']=data_nb['Informativeness Men']-data_nb['Informativeness Women']\n",
    "data_nb['Infomativeness_Difference']=data_nb['Infomativeness_Difference'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE - ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "accuracy_men_tree=[]\n",
    "accuracy_women_tree=[]\n",
    "accuracy_bias_tree=[]\n",
    "\n",
    "for i in range(0,len(data_tree)):\n",
    "    acc_men=(data_tree['Confusion Matrix Men'][i][0,0]+data_tree['Confusion Matrix Men'][i][1,1])/(1000*data_tree['Ratio Men'][i])\n",
    "    accuracy_men_tree.append(float(acc_men))\n",
    "    acc_women=(data_tree['Confusion Matrix Women'][i][0,0]+data_tree['Confusion Matrix Women'][i][1,1])/(1000*(1-data_tree['Ratio Men'][i]))\n",
    "    accuracy_women_tree.append(float(acc_women))\n",
    "    acc_bias=acc_men-acc_women\n",
    "    accuracy_bias_tree.append(float(acc_bias))\n",
    "    acc=(data_tree['Confusion Matrix Men'][i][0,0]+data_tree['Confusion Matrix Men'][i][1,1]+data_tree['Confusion Matrix Women'][i][0,0]+data_tree['Confusion Matrix Women'][i][1,1])/1000\n",
    "    accuracy.append(acc)\n",
    "\n",
    "data_tree['Accuracy Men']=accuracy_men_tree\n",
    "data_tree[\"Accuracy Women\"]=accuracy_women_tree\n",
    "data_tree['Bias']=accuracy_bias_tree\n",
    "data_tree['Accuracy']=accuracy\n",
    "\n",
    "data_tree['Absolute Bias']=data_tree['Bias'].abs()\n",
    "data_tree['Absolute Difference']=data_tree['Difference Probabilities'].abs()\n",
    "data_tree['Informativeness Men']=data_tree['Probability Men'].astype(float)-([0.5]*len(data))\n",
    "data_tree['Informativeness Men']=data_tree['Informativeness Men'].abs().round(2)\n",
    "data_tree['Informativeness Women']=data_tree['Probability Women'].astype(float)-([0.5]*len(data))\n",
    "data_tree['Informativeness Women']=data_tree['Informativeness Women'].abs().round(2)\n",
    "data_tree['Infomativeness_Difference']=data_tree['Informativeness Men']-data_tree['Informativeness Women']\n",
    "data_tree['Infomativeness_Difference']=data_tree['Infomativeness_Difference'].round(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Difference Probabilities':'Difference_Probabilities',\n",
    "                          'Probability Men':'Probability_Men',\n",
    "                          'Ratio Men':'Ratio_Men'}, \n",
    "                 inplace=True)\n",
    "\n",
    "data_clean.rename(columns={'Difference Probabilities':'Difference_Probabilities',\n",
    "                          'Probability Men':'Probability_Men',\n",
    "                          'Ratio Men':'Ratio_Men'}, \n",
    "                 inplace=True)\n",
    "\n",
    "data_nosex.rename(columns={'Difference Probabilities':'Difference_Probabilities',\n",
    "                          'Probability Men':'Probability_Men',\n",
    "                          'Ratio Men':'Ratio_Men'}, \n",
    "                 inplace=True)\n",
    "\n",
    "data_nosexinf.rename(columns={'Difference Probabilities':'Difference_Probabilities',\n",
    "                          'Probability Men':'Probability_Men',\n",
    "                          'Ratio Men':'Ratio_Men'}, \n",
    "                 inplace=True)\n",
    "\n",
    "data_nb.rename(columns={'Difference Probabilities':'Difference_Probabilities',\n",
    "                          'Probability Men':'Probability_Men',\n",
    "                          'Ratio Men':'Ratio_Men'}, \n",
    "                 inplace=True)\n",
    "\n",
    "data_tree.rename(columns={'Difference Probabilities':'Difference_Probabilities',\n",
    "                          'Probability Men':'Probability_Men',\n",
    "                          'Ratio Men':'Ratio_Men'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets Fixed for Ratio Men\n",
    "data_50=data[data['Ratio_Men'].astype(str)=='0.50']\n",
    "data_65=data[data['Ratio_Men'].astype(str)=='0.65']\n",
    "data_80=data[data['Ratio_Men'].astype(str)=='0.80']\n",
    "data_95=data[data['Ratio_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Probability Difference\n",
    "data_dn15=data[data['Difference_Probabilities'].astype(str)=='-0.15']\n",
    "data_dn30=data[data['Difference_Probabilities'].astype(str)=='-0.30']\n",
    "data_dn45=data[data['Difference_Probabilities'].astype(str)=='-0.45']\n",
    "data_d00=data[data['Difference_Probabilities'].astype(str)=='0.00']\n",
    "data_d15=data[data['Difference_Probabilities'].astype(str)=='0.15']\n",
    "data_d30=data[data['Difference_Probabilities'].astype(str)=='0.30']\n",
    "data_d45=data[data['Difference_Probabilities'].astype(str)=='0.45']\n",
    "\n",
    "#Datasets Fixed for Probability Men\n",
    "data_p05=data[data['Probability_Men'].astype(str)=='0.05']\n",
    "data_p20=data[data['Probability_Men'].astype(str)=='0.20']\n",
    "data_p35=data[data['Probability_Men'].astype(str)=='0.35']\n",
    "data_p50=data[data['Probability_Men'].astype(str)=='0.50']\n",
    "data_p65=data[data['Probability_Men'].astype(str)=='0.65']\n",
    "data_p80=data[data['Probability_Men'].astype(str)=='0.80']\n",
    "data_p95=data[data['Probability_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Ratio Men\n",
    "data_nosex_50=data_nosex[data_nosex['Ratio_Men'].astype(str)=='0.50']\n",
    "data_nosex_65=data_nosex[data_nosex['Ratio_Men'].astype(str)=='0.65']\n",
    "data_nosex_80=data_nosex[data_nosex['Ratio_Men'].astype(str)=='0.80']\n",
    "data_nosex_95=data_nosex[data_nosex['Ratio_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Probability Difference\n",
    "data_nosex_dn15=data_nosex[data_nosex['Difference_Probabilities'].astype(str)=='-0.15']\n",
    "data_nosex_dn30=data_nosex[data_nosex['Difference_Probabilities'].astype(str)=='-0.30']\n",
    "data_nosex_dn45=data_nosex[data_nosex['Difference_Probabilities'].astype(str)=='-0.45']\n",
    "data_nosex_d00=data_nosex[data_nosex['Difference_Probabilities'].astype(str)=='0.00']\n",
    "data_nosex_d15=data_nosex[data_nosex['Difference_Probabilities'].astype(str)=='0.15']\n",
    "data_nosex_d30=data_nosex[data_nosex['Difference_Probabilities'].astype(str)=='0.30']\n",
    "data_nosex_d45=data_nosex[data_nosex['Difference_Probabilities'].astype(str)=='0.45']\n",
    "\n",
    "#Datasets Fixed for Probability Men\n",
    "data_nosex_p05=data_nosex[data_nosex['Probability_Men'].astype(str)=='0.05']\n",
    "data_nosex_p20=data_nosex[data_nosex['Probability_Men'].astype(str)=='0.20']\n",
    "data_nosex_p35=data_nosex[data_nosex['Probability_Men'].astype(str)=='0.35']\n",
    "data_nosex_p50=data_nosex[data_nosex['Probability_Men'].astype(str)=='0.50']\n",
    "data_nosex_p65=data_nosex[data_nosex['Probability_Men'].astype(str)=='0.65']\n",
    "data_nosex_p80=data_nosex[data_nosex['Probability_Men'].astype(str)=='0.80']\n",
    "data_nosex_p95=data_nosex[data_nosex['Probability_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Ratio Men\n",
    "data_nosexinf_50=data_nosexinf[data_nosexinf['Ratio_Men'].astype(str)=='0.50']\n",
    "data_nosexinf_65=data_nosexinf[data_nosexinf['Ratio_Men'].astype(str)=='0.65']\n",
    "data_nosexinf_80=data_nosexinf[data_nosexinf['Ratio_Men'].astype(str)=='0.80']\n",
    "data_nosexinf_95=data_nosexinf[data_nosexinf['Ratio_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Probability Difference\n",
    "data_nosexinf_dn15=data_nosexinf[data_nosexinf['Difference_Probabilities'].astype(str)=='-0.15']\n",
    "data_nosexinf_dn30=data_nosexinf[data_nosexinf['Difference_Probabilities'].astype(str)=='-0.30']\n",
    "data_nosexinf_dn45=data_nosexinf[data_nosexinf['Difference_Probabilities'].astype(str)=='-0.45']\n",
    "data_nosexinf_d00=data_nosexinf[data_nosexinf['Difference_Probabilities'].astype(str)=='0.00']\n",
    "data_nosexinf_d15=data_nosexinf[data_nosexinf['Difference_Probabilities'].astype(str)=='0.15']\n",
    "data_nosexinf_d30=data_nosexinf[data_nosexinf['Difference_Probabilities'].astype(str)=='0.30']\n",
    "data_nosexinf_d45=data_nosexinf[data_nosexinf['Difference_Probabilities'].astype(str)=='0.45']\n",
    "\n",
    "#Datasets Fixed for Probability Men\n",
    "data_nosexinf_p05=data_nosexinf[data_nosexinf['Probability_Men'].astype(str)=='0.05']\n",
    "data_nosexinf_p20=data_nosexinf[data_nosexinf['Probability_Men'].astype(str)=='0.20']\n",
    "data_nosexinf_p35=data_nosexinf[data_nosexinf['Probability_Men'].astype(str)=='0.35']\n",
    "data_nosexinf_p50=data_nosexinf[data_nosexinf['Probability_Men'].astype(str)=='0.50']\n",
    "data_nosexinf_p65=data_nosexinf[data_nosexinf['Probability_Men'].astype(str)=='0.65']\n",
    "data_nosexinf_p80=data_nosexinf[data_nosexinf['Probability_Men'].astype(str)=='0.80']\n",
    "data_nosexinf_p95=data_nosexinf[data_nosexinf['Probability_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Ratio Men\n",
    "data_nb_50=data_nb[data_nb['Ratio_Men'].astype(str)=='0.50']\n",
    "data_nb_65=data_nb[data_nb['Ratio_Men'].astype(str)=='0.65']\n",
    "data_nb_80=data_nb[data_nb['Ratio_Men'].astype(str)=='0.80']\n",
    "data_nb_95=data_nb[data_nb['Ratio_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Probability Difference\n",
    "data_nb_dn15=data_nb[data_nb['Difference_Probabilities'].astype(str)=='-0.15']\n",
    "data_nb_dn30=data_nb[data_nb['Difference_Probabilities'].astype(str)=='-0.30']\n",
    "data_nb_dn45=data_nb[data_nb['Difference_Probabilities'].astype(str)=='-0.45']\n",
    "data_nb_d00=data_nb[data_nb['Difference_Probabilities'].astype(str)=='0.00']\n",
    "data_nb_d15=data_nb[data_nb['Difference_Probabilities'].astype(str)=='0.15']\n",
    "data_nb_d30=data_nb[data_nb['Difference_Probabilities'].astype(str)=='0.30']\n",
    "data_nb_d45=data_nb[data_nb['Difference_Probabilities'].astype(str)=='0.45']\n",
    "\n",
    "#Datasets Fixed for Probability Men\n",
    "data_nb_p05=data_nb[data_nb['Probability_Men'].astype(str)=='0.05']\n",
    "data_nb_p20=data_nb[data_nb['Probability_Men'].astype(str)=='0.20']\n",
    "data_nb_p35=data_nb[data_nb['Probability_Men'].astype(str)=='0.35']\n",
    "data_nb_p50=data_nb[data_nb['Probability_Men'].astype(str)=='0.50']\n",
    "data_nb_p65=data_nb[data_nb['Probability_Men'].astype(str)=='0.65']\n",
    "data_nb_p80=data_nb[data_nb['Probability_Men'].astype(str)=='0.80']\n",
    "data_nb_p95=data_nb[data_nb['Probability_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Ratio Men\n",
    "data_tree_50=data_tree[data_tree['Ratio_Men'].astype(str)=='0.50']\n",
    "data_tree_65=data_tree[data_tree['Ratio_Men'].astype(str)=='0.65']\n",
    "data_tree_80=data_tree[data_tree['Ratio_Men'].astype(str)=='0.80']\n",
    "data_tree_95=data_tree[data_tree['Ratio_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Probability Difference\n",
    "data_tree_dn15=data_tree[data_tree['Difference_Probabilities'].astype(str)=='-0.15']\n",
    "data_tree_dn30=data_tree[data_tree['Difference_Probabilities'].astype(str)=='-0.30']\n",
    "data_tree_dn45=data_tree[data_tree['Difference_Probabilities'].astype(str)=='-0.45']\n",
    "data_tree_d00=data_tree[data_tree['Difference_Probabilities'].astype(str)=='0.00']\n",
    "data_tree_d15=data_tree[data_tree['Difference_Probabilities'].astype(str)=='0.15']\n",
    "data_tree_d30=data_tree[data_tree['Difference_Probabilities'].astype(str)=='0.30']\n",
    "data_tree_d45=data_tree[data_tree['Difference_Probabilities'].astype(str)=='0.45']\n",
    "\n",
    "#Datasets Fixed for Probability Men\n",
    "data_tree_p05=data_tree[data_tree['Probability_Men'].astype(str)=='0.05']\n",
    "data_tree_p20=data_tree[data_tree['Probability_Men'].astype(str)=='0.20']\n",
    "data_tree_p35=data_tree[data_tree['Probability_Men'].astype(str)=='0.35']\n",
    "data_tree_p50=data_tree[data_tree['Probability_Men'].astype(str)=='0.50']\n",
    "data_tree_p65=data_tree[data_tree['Probability_Men'].astype(str)=='0.65']\n",
    "data_tree_p80=data_tree[data_tree['Probability_Men'].astype(str)=='0.80']\n",
    "data_tree_p95=data_tree[data_tree['Probability_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Ratio Men\n",
    "data_50_clean=data_clean[data_clean['Ratio_Men'].astype(str)=='0.50']\n",
    "data_65_clean=data_clean[data_clean['Ratio_Men'].astype(str)=='0.65']\n",
    "data_80_clean=data_clean[data_clean['Ratio_Men'].astype(str)=='0.80']\n",
    "data_95_clean=data_clean[data_clean['Ratio_Men'].astype(str)=='0.95']\n",
    "\n",
    "#Datasets Fixed for Probability Difference\n",
    "data_dn15_clean=data_clean[data_clean['Difference_Probabilities'].astype(str)=='-0.15']\n",
    "data_dn30_clean=data_clean[data_clean['Difference_Probabilities'].astype(str)=='-0.30']\n",
    "data_dn45_clean=data_clean[data_clean['Difference_Probabilities'].astype(str)=='-0.45']\n",
    "data_d00_clean=data_clean[data_clean['Difference_Probabilities'].astype(str)=='0.00']\n",
    "data_d15_clean=data_clean[data_clean['Difference_Probabilities'].astype(str)=='0.15']\n",
    "data_d30_clean=data_clean[data_clean['Difference_Probabilities'].astype(str)=='0.30']\n",
    "data_d45_clean=data_clean[data_clean['Difference_Probabilities'].astype(str)=='0.45']\n",
    "\n",
    "#Datasets Fixed for Probability Men\n",
    "data_p05_clean=data_clean[data_clean['Probability_Men'].astype(str)=='0.05']\n",
    "data_p20_clean=data_clean[data_clean['Probability_Men'].astype(str)=='0.20']\n",
    "data_p35_clean=data_clean[data_clean['Probability_Men'].astype(str)=='0.35']\n",
    "data_p50_clean=data_clean[data_clean['Probability_Men'].astype(str)=='0.50']\n",
    "data_p65_clean=data_clean[data_clean['Probability_Men'].astype(str)=='0.65']\n",
    "data_p80_clean=data_clean[data_clean['Probability_Men'].astype(str)=='0.80']\n",
    "data_p95_clean=data_clean[data_clean['Probability_Men'].astype(str)=='0.95']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp. Group</th>\n",
       "      <th># Dataset</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Ratio_Men</th>\n",
       "      <th>Probability_Men</th>\n",
       "      <th>Probability Women</th>\n",
       "      <th>Difference_Probabilities</th>\n",
       "      <th>Confusion Matrix Men</th>\n",
       "      <th>Confusion Matrix Women</th>\n",
       "      <th>Accuracy Men</th>\n",
       "      <th>Accuracy Women</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Absolute Bias</th>\n",
       "      <th>Absolute Difference</th>\n",
       "      <th>Informativeness Men</th>\n",
       "      <th>Informativeness Women</th>\n",
       "      <th>Infomativeness_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2041</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[[474, 0], [23, 3]]</td>\n",
       "      <td>[[465, 2], [27, 6]]</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>708</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[[477, 7], [13, 3]]</td>\n",
       "      <td>[[479, 0], [15, 6]]</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4559</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[[465, 0], [35, 0]]</td>\n",
       "      <td>[[472, 0], [28, 0]]</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.944</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3465</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[[475, 0], [25, 0]]</td>\n",
       "      <td>[[462, 0], [38, 0]]</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3206</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[[483, 0], [17, 0]]</td>\n",
       "      <td>[[480, 0], [20, 0]]</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Exp. Group # Dataset  Seed Ratio_Men Probability_Men Probability Women  \\\n",
       "1          1         2  2041      0.50            0.05              0.05   \n",
       "2          1         3   708      0.50            0.05              0.05   \n",
       "3          1         4  4559      0.50            0.05              0.05   \n",
       "4          1         5  3465      0.50            0.05              0.05   \n",
       "5          1         6  3206      0.50            0.05              0.05   \n",
       "\n",
       "  Difference_Probabilities Confusion Matrix Men Confusion Matrix Women  \\\n",
       "1                     0.00  [[474, 0], [23, 3]]    [[465, 2], [27, 6]]   \n",
       "2                     0.00  [[477, 7], [13, 3]]    [[479, 0], [15, 6]]   \n",
       "3                     0.00  [[465, 0], [35, 0]]    [[472, 0], [28, 0]]   \n",
       "4                     0.00  [[475, 0], [25, 0]]    [[462, 0], [38, 0]]   \n",
       "5                     0.00  [[483, 0], [17, 0]]    [[480, 0], [20, 0]]   \n",
       "\n",
       "   Accuracy Men  Accuracy Women   Bias  Accuracy  Absolute Bias  \\\n",
       "1         0.954           0.942  0.012     0.948          0.012   \n",
       "2         0.960           0.970 -0.010     0.965          0.010   \n",
       "3         0.930           0.944 -0.014     0.937          0.014   \n",
       "4         0.950           0.924  0.026     0.937          0.026   \n",
       "5         0.966           0.960  0.006     0.963          0.006   \n",
       "\n",
       "  Absolute Difference  Informativeness Men  Informativeness Women  \\\n",
       "1                0.00                 0.45                   0.45   \n",
       "2                0.00                 0.45                   0.45   \n",
       "3                0.00                 0.45                   0.45   \n",
       "4                0.00                 0.45                   0.45   \n",
       "5                0.00                 0.45                   0.45   \n",
       "\n",
       "   Infomativeness_Difference  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "5                        0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM (NB)\n",
      "count    81400.000000\n",
      "mean         0.831147\n",
      "std          0.065855\n",
      "min          0.108000\n",
      "25%          0.798000\n",
      "50%          0.821000\n",
      "75%          0.865000\n",
      "max          0.974000\n",
      "Name: Accuracy, dtype: float64\n",
      "Accuracy Bias of SVM (NB)\n",
      "count    81400.000000\n",
      "mean         0.052943\n",
      "std          0.191391\n",
      "min         -0.893684\n",
      "25%         -0.039780\n",
      "50%          0.018022\n",
      "75%          0.129474\n",
      "max          0.874737\n",
      "Name: Bias, dtype: float64\n",
      "Absolute Accuracy Bias of SVM (NB)\n",
      "count    81400.000000\n",
      "mean         0.133397\n",
      "std          0.147100\n",
      "min          0.000000\n",
      "25%          0.028000\n",
      "50%          0.081250\n",
      "75%          0.199176\n",
      "max          0.893684\n",
      "Name: Absolute Bias, dtype: float64\n",
      "Accuracy of SVM (Tree)\n",
      "count    81400.000000\n",
      "mean         0.801452\n",
      "std          0.062686\n",
      "min          0.658000\n",
      "25%          0.752000\n",
      "50%          0.786000\n",
      "75%          0.836000\n",
      "max          0.966000\n",
      "Name: Accuracy, dtype: float64\n",
      "Accuracy Bias of SVM (Tree)\n",
      "count    81400.000000\n",
      "mean         0.010715\n",
      "std          0.108963\n",
      "min         -0.300000\n",
      "25%         -0.057500\n",
      "50%          0.006000\n",
      "75%          0.078000\n",
      "max          0.490526\n",
      "Name: Bias, dtype: float64\n",
      "Absolute Accuracy Bias of SVM (Tree)\n",
      "count    81400.000000\n",
      "mean         0.085450\n",
      "std          0.068454\n",
      "min          0.000000\n",
      "25%          0.028000\n",
      "50%          0.068000\n",
      "75%          0.130526\n",
      "max          0.490526\n",
      "Name: Absolute Bias, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of SVM (NB)\")\n",
    "print(data_nb['Accuracy'].describe())\n",
    "print(\"Accuracy Bias of SVM (NB)\")\n",
    "print(data_nb['Bias'].describe())\n",
    "print(\"Absolute Accuracy Bias of SVM (NB)\")\n",
    "print(data_nb['Absolute Bias'].describe())\n",
    "\n",
    "print(\"Accuracy of SVM (Tree)\")\n",
    "print(data_tree['Accuracy'].describe())\n",
    "print(\"Accuracy Bias of SVM (Tree)\")\n",
    "print(data_tree['Bias'].describe())\n",
    "print(\"Absolute Accuracy Bias of SVM (Tree)\")\n",
    "print(data_tree['Absolute Bias'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM (ALL DATA)\n",
      "count    81400.000000\n",
      "mean         0.859668\n",
      "std          0.046186\n",
      "min          0.767000\n",
      "25%          0.823000\n",
      "50%          0.849000\n",
      "75%          0.887000\n",
      "max          0.975000\n",
      "Name: Accuracy, dtype: float64\n",
      "Accuracy Bias of SVM (ALL DATA)\n",
      "count    81400.000000\n",
      "mean         0.000511\n",
      "std          0.087089\n",
      "min         -0.213684\n",
      "25%         -0.056000\n",
      "50%         -0.001250\n",
      "75%          0.056000\n",
      "max          0.383158\n",
      "Name: Bias, dtype: float64\n",
      "Absolute Accuracy Bias of SVM (ALL DATA)\n",
      "count    81400.000000\n",
      "mean         0.068706\n",
      "std          0.053518\n",
      "min          0.000000\n",
      "25%          0.023736\n",
      "50%          0.056000\n",
      "75%          0.106250\n",
      "max          0.383158\n",
      "Name: Absolute Bias, dtype: float64\n",
      "Accuracy of SVM (NO GENDER)\n",
      "count    81400.000000\n",
      "mean         0.857893\n",
      "std          0.046065\n",
      "min          0.769000\n",
      "25%          0.822000\n",
      "50%          0.846000\n",
      "75%          0.884000\n",
      "max          0.975000\n",
      "Name: Accuracy, dtype: float64\n",
      "Accuracy Bias of SVM (NO GENDER)\n",
      "count    81400.000000\n",
      "mean         0.005121\n",
      "std          0.089106\n",
      "min         -0.226000\n",
      "25%         -0.052747\n",
      "50%          0.000000\n",
      "75%          0.059560\n",
      "max          0.421053\n",
      "Name: Bias, dtype: float64\n",
      "Absolute Accuracy Bias of SVM (NO GENDER)\n",
      "count    81400.000000\n",
      "mean         0.069652\n",
      "std          0.055810\n",
      "min          0.000000\n",
      "25%          0.023750\n",
      "50%          0.056000\n",
      "75%          0.107500\n",
      "max          0.421053\n",
      "Name: Absolute Bias, dtype: float64\n",
      "Accuracy of SVM (NO GENDER INF)\n",
      "count    81400.000000\n",
      "mean         0.856824\n",
      "std          0.045910\n",
      "min          0.766000\n",
      "25%          0.821000\n",
      "50%          0.845000\n",
      "75%          0.883000\n",
      "max          0.975000\n",
      "Name: Accuracy, dtype: float64\n",
      "Accuracy Bias of SVM (NO GENDER INF)\n",
      "count    81400.000000\n",
      "mean         0.008578\n",
      "std          0.090754\n",
      "min         -0.206316\n",
      "25%         -0.050000\n",
      "50%          0.001099\n",
      "75%          0.062105\n",
      "max          0.630526\n",
      "Name: Bias, dtype: float64\n",
      "Absolute Accuracy Bias of SVM (NO GENDER INF)\n",
      "count    81400.000000\n",
      "mean         0.070112\n",
      "std          0.058260\n",
      "min          0.000000\n",
      "25%          0.023077\n",
      "50%          0.056000\n",
      "75%          0.107473\n",
      "max          0.630526\n",
      "Name: Absolute Bias, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of SVM (ALL DATA)\")\n",
    "print(data['Accuracy'].describe())\n",
    "print(\"Accuracy Bias of SVM (ALL DATA)\")\n",
    "print(data['Bias'].describe())\n",
    "print(\"Absolute Accuracy Bias of SVM (ALL DATA)\")\n",
    "print(data['Absolute Bias'].describe())\n",
    "\n",
    "print(\"Accuracy of SVM (NO GENDER)\")\n",
    "print(data_nosex['Accuracy'].describe())\n",
    "print(\"Accuracy Bias of SVM (NO GENDER)\")\n",
    "print(data_nosex['Bias'].describe())\n",
    "print(\"Absolute Accuracy Bias of SVM (NO GENDER)\")\n",
    "print(data_nosex['Absolute Bias'].describe())\n",
    "\n",
    "print(\"Accuracy of SVM (NO GENDER INF)\")\n",
    "print(data_nosexinf['Accuracy'].describe())\n",
    "print(\"Accuracy Bias of SVM (NO GENDER INF)\")\n",
    "print(data_nosexinf['Bias'].describe())\n",
    "print(\"Absolute Accuracy Bias of SVM (NO GENDER INF)\")\n",
    "print(data_nosexinf['Absolute Bias'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=2.5)\n",
    "plt.title(\"Bias - Gender Information (Gender and Height) Available for Learner\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"Overview_SVM_ALLDATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=2.5)\n",
    "plt.title(\"Bias - No Gender Available for Learner (Only Genderrelated Weigth)\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_nosex,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"Overview_SVM_NOSEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=2.5)\n",
    "plt.title(\"Bias - No Gender Related Information Available for Learner\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_nosexinf,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"Overview_SVM_NOSEXINF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acmen_sd=data.loc[:,\"Accuracy Men\"].std()\n",
    "acmen_mean=data.loc[:,\"Accuracy Men\"].mean()\n",
    "acwomen_sd=data.loc[:,\"Accuracy Women\"].std()\n",
    "acwomen_mean=data.loc[:,\"Accuracy Women\"].mean()\n",
    "bias_ds=data.loc[:,\"Bias\"].std()\n",
    "bias_mean=data.loc[:,\"Bias\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('possibleacc.pkl', 'rb') as f:\n",
    "    possible_accuracys=pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "am=[]\n",
    "asd=[]\n",
    "amm=[]\n",
    "amsd=[]\n",
    "afm=[]\n",
    "afsd=[]\n",
    "biasm=[]\n",
    "biassd=[]\n",
    "for i in range(1,149): \n",
    "    data_group=data[data['Exp. Group']==i]\n",
    "    am.append(data_group.loc[:,'Accuracy'].mean())\n",
    "    asd.append(data_group.loc[:,'Accuracy'].std())\n",
    "    amm.append(data_group.loc[:,'Accuracy Men'].mean())\n",
    "    amsd.append(data_group.loc[:,'Accuracy Men'].std())\n",
    "    afm.append(data_group.loc[:,'Accuracy Women'].mean())           \n",
    "    afsd.append(data_group.loc[:,'Accuracy Women'].std())\n",
    "    biasm.append(data_group.loc[:,'Bias'].mean())\n",
    "    biassd.append(data_group.loc[:,'Bias'].std())\n",
    "    \n",
    "data_group_svm=pd.DataFrame()\n",
    "data_group_svm['Mean Accuracy']=am\n",
    "data_group_svm['SD Accuracy']=asd\n",
    "data_group_svm['Mean Accuracy Men']=amm\n",
    "data_group_svm['SD Accuracy Men']=amsd\n",
    "data_group_svm['Mean Accuracy Women']=afm\n",
    "data_group_svm['SD Accuracy Women']=afsd\n",
    "data_group_svm['Mean Bias']=biasm\n",
    "data_group_svm['SD Bias']=biassd\n",
    "data_group_svm['Possible Accuracy']=possible_accuracys['possible accuracys']\n",
    "\n",
    "amm=[]\n",
    "amsd=[]\n",
    "afm=[]\n",
    "afsd=[]\n",
    "biasm=[]\n",
    "biassd=[]\n",
    "for i in range(1,49): \n",
    "    data_group_50=data_50[data_50['Exp. Group']==i]\n",
    "    amm.append(data_group_50.loc[:,'Accuracy Men'].mean())\n",
    "    amsd.append(data_group_50.loc[:,'Accuracy Men'].std())\n",
    "    afm.append(data_group_50.loc[:,'Accuracy Women'].mean())           \n",
    "    afsd.append(data_group_50.loc[:,'Accuracy Women'].std())\n",
    "    biasm.append(data_group_50.loc[:,'Bias'].mean())\n",
    "    biassd.append(data_group_50.loc[:,'Bias'].std())\n",
    "    \n",
    "data_group_svm_50=pd.DataFrame()\n",
    "data_group_svm_50['Mean Accuracy Men']=amm\n",
    "data_group_svm_50['SD Accuracy Men']=amsd\n",
    "data_group_svm_50['Mean Accuracy Women']=afm\n",
    "data_group_svm_50['SD Accuracy Women']=afsd\n",
    "data_group_svm_50['Mean Bias']=biasm\n",
    "data_group_svm_50['SD Bias']=biassd\n",
    "\n",
    "amm=[]\n",
    "amsd=[]\n",
    "afm=[]\n",
    "afsd=[]\n",
    "biasm=[]\n",
    "biassd=[]\n",
    "for i in range(48,97): \n",
    "    data_group_65=data_65[data_65['Exp. Group']==i]\n",
    "    amm.append(data_group_65.loc[:,'Accuracy Men'].mean())\n",
    "    amsd.append(data_group_65.loc[:,'Accuracy Men'].std())\n",
    "    afm.append(data_group_65.loc[:,'Accuracy Women'].mean())           \n",
    "    afsd.append(data_group_65.loc[:,'Accuracy Women'].std())\n",
    "    biasm.append(data_group_65.loc[:,'Bias'].mean())\n",
    "    biassd.append(data_group_65.loc[:,'Bias'].std())\n",
    "    \n",
    "data_group_svm_65=pd.DataFrame()\n",
    "data_group_svm_65['Mean Accuracy Men']=amm\n",
    "data_group_svm_65['SD Accuracy Men']=amsd\n",
    "data_group_svm_65['Mean Accuracy Women']=afm\n",
    "data_group_svm_65['SD Accuracy Women']=afsd\n",
    "data_group_svm_65['Mean Bias']=biasm\n",
    "data_group_svm_65['SD Bias']=biassd\n",
    "\n",
    "amm=[]\n",
    "amsd=[]\n",
    "afm=[]\n",
    "afsd=[]\n",
    "biasm=[]\n",
    "biassd=[]\n",
    "group=[]\n",
    "for i in range(97,118): \n",
    "    data_group_80=data_80[data_80['Exp. Group']==i]\n",
    "    amm.append(data_group_80.loc[:,'Accuracy Men'].mean())\n",
    "    amsd.append(data_group_80.loc[:,'Accuracy Men'].std())\n",
    "    afm.append(data_group_80.loc[:,'Accuracy Women'].mean())           \n",
    "    afsd.append(data_group_80.loc[:,'Accuracy Women'].std())\n",
    "    biasm.append(data_group_80.loc[:,'Bias'].mean())\n",
    "    biassd.append(data_group_80.loc[:,'Bias'].std())\n",
    "    group.append(i)\n",
    "    \n",
    "data_group_svm_80=pd.DataFrame()\n",
    "data_group_svm_80['Group']=group\n",
    "data_group_svm_80['Mean Accuracy Men']=amm\n",
    "data_group_svm_80['SD Accuracy Men']=amsd\n",
    "data_group_svm_80['Mean Accuracy Women']=afm\n",
    "data_group_svm_80['SD Accuracy Women']=afsd\n",
    "data_group_svm_80['Mean Bias']=biasm\n",
    "data_group_svm_80['SD Bias']=biassd\n",
    "\n",
    "amm=[]\n",
    "amsd=[]\n",
    "afm=[]\n",
    "afsd=[]\n",
    "biasm=[]\n",
    "biassd=[]\n",
    "group=[]\n",
    "for i in range(118,149): \n",
    "    data_group_95=data_95[data_95['Exp. Group']==i]\n",
    "    amm.append(data_group_95.loc[:,'Accuracy Men'].mean())\n",
    "    amsd.append(data_group_95.loc[:,'Accuracy Men'].std())\n",
    "    afm.append(data_group_95.loc[:,'Accuracy Women'].mean())           \n",
    "    afsd.append(data_group_95.loc[:,'Accuracy Women'].std())\n",
    "    biasm.append(data_group_95.loc[:,'Bias'].mean())\n",
    "    biassd.append(data_group_95.loc[:,'Bias'].std())\n",
    "    group.append(i)\n",
    "    \n",
    "data_group_svm_95=pd.DataFrame()\n",
    "data_group_svm_95['Group']=group\n",
    "data_group_svm_95['Mean Accuracy Men']=amm\n",
    "data_group_svm_95['SD Accuracy Men']=amsd\n",
    "data_group_svm_95['Mean Accuracy Women']=afm\n",
    "data_group_svm_95['SD Accuracy Women']=afsd\n",
    "data_group_svm_95['Mean Bias']=biasm\n",
    "data_group_svm_95['SD Bias']=biassd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "amm=[]\n",
    "amsd=[]\n",
    "afm=[]\n",
    "afsd=[]\n",
    "biasm=[]\n",
    "biassd=[]\n",
    "for i in range(1,149): \n",
    "    data_group=data_nb[data_nb['Exp. Group']==i]\n",
    "    amm.append(data_group.loc[:,'Accuracy Men'].mean())\n",
    "    amsd.append(data_group.loc[:,'Accuracy Men'].std())\n",
    "    afm.append(data_group.loc[:,'Accuracy Women'].mean())           \n",
    "    afsd.append(data_group.loc[:,'Accuracy Women'].std())\n",
    "    biasm.append(data_group.loc[:,'Bias'].mean())\n",
    "    biassd.append(data_group.loc[:,'Bias'].std())\n",
    "    \n",
    "import pandas as pd\n",
    "data_group_nb=pd.DataFrame()\n",
    "data_group_nb['Mean Accuracy Men']=amm\n",
    "data_group_nb['SD Accuracy Men']=amsd\n",
    "data_group_nb['Mean Accuracy Women']=afm\n",
    "data_group_nb['SD Accuracy Women']=afsd\n",
    "data_group_nb['Mean Bias']=biasm\n",
    "data_group_nb['SD Bias']=biassd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amm=[]\n",
    "amsd=[]\n",
    "afm=[]\n",
    "afsd=[]\n",
    "biasm=[]\n",
    "biassd=[]\n",
    "for i in range(1,149): \n",
    "    data_group=data_tree[data_tree['Exp. Group']==i]\n",
    "    amm.append(data_group.loc[:,'Accuracy Men'].mean())\n",
    "    amsd.append(data_group.loc[:,'Accuracy Men'].std())\n",
    "    afm.append(data_group.loc[:,'Accuracy Women'].mean())           \n",
    "    afsd.append(data_group.loc[:,'Accuracy Women'].std())\n",
    "    biasm.append(data_group.loc[:,'Bias'].mean())\n",
    "    biassd.append(data_group.loc[:,'Bias'].std())\n",
    "    \n",
    "import pandas as pd\n",
    "data_group_tree=pd.DataFrame()\n",
    "data_group_tree['Mean Accuracy Men']=amm\n",
    "data_group_tree['SD Accuracy Men']=amsd\n",
    "data_group_tree['Mean Accuracy Women']=afm\n",
    "data_group_tree['SD Accuracy Women']=afsd\n",
    "data_group_tree['Mean Bias']=biasm\n",
    "data_group_tree['SD Bias']=biassd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>SD Accuracy</th>\n",
       "      <th>Mean Accuracy Men</th>\n",
       "      <th>SD Accuracy Men</th>\n",
       "      <th>Mean Accuracy Women</th>\n",
       "      <th>SD Accuracy Women</th>\n",
       "      <th>Mean Bias</th>\n",
       "      <th>SD Bias</th>\n",
       "      <th>Possible Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953202</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.954164</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.952240</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>0.929423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912231</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.957953</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0.866509</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>0.091444</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.888878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.888627</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.957873</td>\n",
       "      <td>0.009869</td>\n",
       "      <td>0.819382</td>\n",
       "      <td>0.016294</td>\n",
       "      <td>0.138491</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.871093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.882271</td>\n",
       "      <td>0.010513</td>\n",
       "      <td>0.957855</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.806687</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>0.151167</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.866886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912693</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>0.868095</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>0.957291</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>-0.089196</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.889964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.867660</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>0.867527</td>\n",
       "      <td>0.015173</td>\n",
       "      <td>0.867793</td>\n",
       "      <td>0.017640</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.849571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.844049</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>0.868124</td>\n",
       "      <td>0.015242</td>\n",
       "      <td>0.819975</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>0.048149</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.831695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.837029</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.868062</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.805996</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.062065</td>\n",
       "      <td>0.024190</td>\n",
       "      <td>0.827573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.845013</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.868684</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>0.821342</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.047342</td>\n",
       "      <td>0.024204</td>\n",
       "      <td>0.832606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.887085</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>0.816713</td>\n",
       "      <td>0.017671</td>\n",
       "      <td>0.957458</td>\n",
       "      <td>0.007726</td>\n",
       "      <td>-0.140745</td>\n",
       "      <td>0.020037</td>\n",
       "      <td>0.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.842375</td>\n",
       "      <td>0.013753</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.016896</td>\n",
       "      <td>0.868007</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>-0.051265</td>\n",
       "      <td>0.022005</td>\n",
       "      <td>0.831505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.818880</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.817236</td>\n",
       "      <td>0.017216</td>\n",
       "      <td>0.820524</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>-0.003287</td>\n",
       "      <td>0.022597</td>\n",
       "      <td>0.813672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.812015</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.816876</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.807153</td>\n",
       "      <td>0.018855</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>0.809535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.817527</td>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.822342</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>0.027202</td>\n",
       "      <td>0.814610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.841938</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.816724</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>0.867153</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>-0.050429</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>0.832027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.880327</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.803127</td>\n",
       "      <td>0.017644</td>\n",
       "      <td>0.957527</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>-0.154400</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.866807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.834858</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.802018</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>0.867698</td>\n",
       "      <td>0.017306</td>\n",
       "      <td>-0.065680</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>0.826414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.811300</td>\n",
       "      <td>0.012082</td>\n",
       "      <td>0.802498</td>\n",
       "      <td>0.016539</td>\n",
       "      <td>0.820102</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>-0.017604</td>\n",
       "      <td>0.023230</td>\n",
       "      <td>0.808555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.804956</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.802302</td>\n",
       "      <td>0.016392</td>\n",
       "      <td>0.807611</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>0.025009</td>\n",
       "      <td>0.804405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.811867</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>0.802513</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.821222</td>\n",
       "      <td>0.018126</td>\n",
       "      <td>-0.018709</td>\n",
       "      <td>0.026429</td>\n",
       "      <td>0.809538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.834891</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>0.802305</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>0.867476</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>-0.065171</td>\n",
       "      <td>0.021902</td>\n",
       "      <td>0.826904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.879767</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.802171</td>\n",
       "      <td>0.016666</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>-0.155193</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.866288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.844824</td>\n",
       "      <td>0.011362</td>\n",
       "      <td>0.821738</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>0.867909</td>\n",
       "      <td>0.018669</td>\n",
       "      <td>-0.046171</td>\n",
       "      <td>0.024841</td>\n",
       "      <td>0.833136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.820336</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.821476</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>0.819196</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>0.815345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.814415</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.821411</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>0.807418</td>\n",
       "      <td>0.018367</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>0.811192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.821447</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>0.820967</td>\n",
       "      <td>0.014417</td>\n",
       "      <td>0.821927</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>0.816262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.844656</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.867764</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.833692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.889207</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>0.820945</td>\n",
       "      <td>0.013651</td>\n",
       "      <td>0.957469</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>-0.136524</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.873056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.844976</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.870571</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.819382</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>0.831808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.838371</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.870651</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>0.806091</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>0.064560</td>\n",
       "      <td>0.022623</td>\n",
       "      <td>0.827676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.865524</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.868796</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.803345</td>\n",
       "      <td>0.052719</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>0.056337</td>\n",
       "      <td>0.847469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.866535</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.868666</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>0.826036</td>\n",
       "      <td>0.055475</td>\n",
       "      <td>0.042630</td>\n",
       "      <td>0.058829</td>\n",
       "      <td>0.848032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.825709</td>\n",
       "      <td>0.012920</td>\n",
       "      <td>0.818882</td>\n",
       "      <td>0.013522</td>\n",
       "      <td>0.955418</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.819450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.820767</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>0.818664</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.050146</td>\n",
       "      <td>-0.042063</td>\n",
       "      <td>0.049727</td>\n",
       "      <td>0.815357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.818705</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.819016</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.812800</td>\n",
       "      <td>0.061486</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.062455</td>\n",
       "      <td>0.813634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>0.818892</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.805964</td>\n",
       "      <td>0.054168</td>\n",
       "      <td>0.012928</td>\n",
       "      <td>0.056615</td>\n",
       "      <td>0.813218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.818876</td>\n",
       "      <td>0.013121</td>\n",
       "      <td>0.818697</td>\n",
       "      <td>0.013577</td>\n",
       "      <td>0.822291</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>0.060920</td>\n",
       "      <td>0.813806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.821353</td>\n",
       "      <td>0.013399</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>-0.049102</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>0.815823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.812333</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.804926</td>\n",
       "      <td>0.012515</td>\n",
       "      <td>0.953055</td>\n",
       "      <td>0.033242</td>\n",
       "      <td>-0.148128</td>\n",
       "      <td>0.034649</td>\n",
       "      <td>0.810679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.807495</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>0.804867</td>\n",
       "      <td>0.012714</td>\n",
       "      <td>0.857418</td>\n",
       "      <td>0.053849</td>\n",
       "      <td>-0.052551</td>\n",
       "      <td>0.055117</td>\n",
       "      <td>0.806505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.805173</td>\n",
       "      <td>0.012744</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.812982</td>\n",
       "      <td>0.062184</td>\n",
       "      <td>-0.008220</td>\n",
       "      <td>0.061155</td>\n",
       "      <td>0.804864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.805135</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>0.804942</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.808800</td>\n",
       "      <td>0.053344</td>\n",
       "      <td>-0.003858</td>\n",
       "      <td>0.054325</td>\n",
       "      <td>0.804396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.806004</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>0.805135</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.822509</td>\n",
       "      <td>0.058271</td>\n",
       "      <td>-0.017374</td>\n",
       "      <td>0.059001</td>\n",
       "      <td>0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.808060</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.804884</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>0.037943</td>\n",
       "      <td>-0.063516</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>0.807033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.811893</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.804622</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.950036</td>\n",
       "      <td>0.027335</td>\n",
       "      <td>-0.145414</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>0.810795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.823482</td>\n",
       "      <td>0.010580</td>\n",
       "      <td>0.821734</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.856691</td>\n",
       "      <td>0.054868</td>\n",
       "      <td>-0.034957</td>\n",
       "      <td>0.058423</td>\n",
       "      <td>0.817813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.821797</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.060403</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.062426</td>\n",
       "      <td>0.816127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.820976</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>0.821734</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>0.806582</td>\n",
       "      <td>0.053806</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.053739</td>\n",
       "      <td>0.815677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.821409</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.825891</td>\n",
       "      <td>0.056635</td>\n",
       "      <td>-0.004482</td>\n",
       "      <td>0.056440</td>\n",
       "      <td>0.816242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.824027</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.821694</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.868364</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>-0.046670</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>0.818310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.821646</td>\n",
       "      <td>0.011474</td>\n",
       "      <td>0.951236</td>\n",
       "      <td>0.026903</td>\n",
       "      <td>-0.129590</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.822079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.865758</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.868565</td>\n",
       "      <td>0.010982</td>\n",
       "      <td>0.812436</td>\n",
       "      <td>0.057307</td>\n",
       "      <td>0.056128</td>\n",
       "      <td>0.059215</td>\n",
       "      <td>0.848035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.865602</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.868834</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.804182</td>\n",
       "      <td>0.053011</td>\n",
       "      <td>0.064653</td>\n",
       "      <td>0.052764</td>\n",
       "      <td>0.847607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.866016</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.868191</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.058436</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.059212</td>\n",
       "      <td>0.848185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.868789</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.868769</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.869164</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>0.850227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.872885</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>0.868718</td>\n",
       "      <td>0.011060</td>\n",
       "      <td>0.952073</td>\n",
       "      <td>0.027838</td>\n",
       "      <td>-0.083355</td>\n",
       "      <td>0.029368</td>\n",
       "      <td>0.853997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.949364</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.956978</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.804691</td>\n",
       "      <td>0.049439</td>\n",
       "      <td>0.152287</td>\n",
       "      <td>0.049036</td>\n",
       "      <td>0.923392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.949265</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.956545</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.810945</td>\n",
       "      <td>0.061967</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.062990</td>\n",
       "      <td>0.923985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.950060</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.955428</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.848073</td>\n",
       "      <td>0.047221</td>\n",
       "      <td>0.107355</td>\n",
       "      <td>0.046632</td>\n",
       "      <td>0.926010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.953956</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.953916</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.954727</td>\n",
       "      <td>0.025561</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>0.025282</td>\n",
       "      <td>0.929782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean Accuracy  SD Accuracy  Mean Accuracy Men  SD Accuracy Men  \\\n",
       "0         0.953202     0.007558           0.954164         0.009906   \n",
       "1         0.912231     0.009916           0.957953         0.008923   \n",
       "2         0.888627     0.009070           0.957873         0.009869   \n",
       "3         0.882271     0.010513           0.957855         0.009390   \n",
       "4         0.912693     0.008220           0.868095         0.015124   \n",
       "5         0.867660     0.012089           0.867527         0.015173   \n",
       "6         0.844049     0.010875           0.868124         0.015242   \n",
       "7         0.837029     0.011763           0.868062         0.014790   \n",
       "8         0.845013     0.011049           0.868684         0.014707   \n",
       "9         0.887085     0.009252           0.816713         0.017671   \n",
       "10        0.842375     0.013753           0.816742         0.016896   \n",
       "11        0.818880     0.013468           0.817236         0.017216   \n",
       "12        0.812015     0.012026           0.816876         0.017104   \n",
       "13        0.819935     0.011486           0.817527         0.017693   \n",
       "14        0.841938     0.011917           0.816724         0.017384   \n",
       "15        0.880327     0.008924           0.803127         0.017644   \n",
       "16        0.834858     0.012355           0.802018         0.017168   \n",
       "17        0.811300     0.012082           0.802498         0.016539   \n",
       "18        0.804956     0.011979           0.802302         0.016392   \n",
       "19        0.811867     0.012091           0.802513         0.017694   \n",
       "20        0.834891     0.011780           0.802305         0.016586   \n",
       "21        0.879767     0.008797           0.802171         0.016666   \n",
       "22        0.844824     0.011362           0.821738         0.014771   \n",
       "23        0.820336     0.011492           0.821476         0.014721   \n",
       "24        0.814415     0.012386           0.821411         0.014408   \n",
       "25        0.821447     0.011240           0.820967         0.014417   \n",
       "26        0.844656     0.011212           0.821549         0.014288   \n",
       "27        0.889207     0.008014           0.820945         0.013651   \n",
       "28        0.844976     0.012264           0.870571         0.014523   \n",
       "29        0.838371     0.012370           0.870651         0.014221   \n",
       "..             ...          ...                ...              ...   \n",
       "118       0.865524     0.011892           0.868796         0.012700   \n",
       "119       0.866535     0.012046           0.868666         0.012799   \n",
       "120       0.825709     0.012920           0.818882         0.013522   \n",
       "121       0.820767     0.013812           0.818664         0.013860   \n",
       "122       0.818705     0.013345           0.819016         0.013547   \n",
       "123       0.818245     0.013225           0.818892         0.013782   \n",
       "124       0.818876     0.013121           0.818697         0.013577   \n",
       "125       0.821353     0.013399           0.818898         0.013452   \n",
       "126       0.812333     0.012125           0.804926         0.012515   \n",
       "127       0.807495     0.012419           0.804867         0.012714   \n",
       "128       0.805173     0.012744           0.804762         0.012427   \n",
       "129       0.805135     0.012240           0.804942         0.012470   \n",
       "130       0.806004     0.012408           0.805135         0.012547   \n",
       "131       0.808060     0.012172           0.804884         0.012665   \n",
       "132       0.811893     0.011596           0.804622         0.012634   \n",
       "133       0.823482     0.010580           0.821734         0.011404   \n",
       "134       0.821267     0.011008           0.821797         0.011418   \n",
       "135       0.820976     0.011214           0.821734         0.011153   \n",
       "136       0.821633     0.011365           0.821409         0.011244   \n",
       "137       0.824027     0.010714           0.821694         0.011239   \n",
       "138       0.828125     0.010700           0.821646         0.011474   \n",
       "139       0.865758     0.010593           0.868565         0.010982   \n",
       "140       0.865602     0.011008           0.868834         0.010902   \n",
       "141       0.866016     0.010971           0.868191         0.011058   \n",
       "142       0.868789     0.010594           0.868769         0.010801   \n",
       "143       0.872885     0.010676           0.868718         0.011060   \n",
       "144       0.949364     0.007066           0.956978         0.006643   \n",
       "145       0.949265     0.006732           0.956545         0.006633   \n",
       "146       0.950060     0.007477           0.955428         0.007087   \n",
       "147       0.953956     0.007594           0.953916         0.007634   \n",
       "\n",
       "     Mean Accuracy Women  SD Accuracy Women  Mean Bias   SD Bias  \\\n",
       "0               0.952240           0.009450   0.001924  0.012096   \n",
       "1               0.866509           0.018270   0.091444  0.020821   \n",
       "2               0.819382           0.016294   0.138491  0.019918   \n",
       "3               0.806687           0.018435   0.151167  0.020345   \n",
       "4               0.957291           0.007814  -0.089196  0.017586   \n",
       "5               0.867793           0.017640  -0.000265  0.022321   \n",
       "6               0.819975           0.016605   0.048149  0.023302   \n",
       "7               0.805996           0.018724   0.062065  0.024190   \n",
       "8               0.821342           0.017911   0.047342  0.024204   \n",
       "9               0.957458           0.007726  -0.140745  0.020037   \n",
       "10              0.868007           0.018301  -0.051265  0.022005   \n",
       "11              0.820524           0.017937  -0.003287  0.022597   \n",
       "12              0.807153           0.018855   0.009724  0.026788   \n",
       "13              0.822342           0.017910  -0.004815  0.027202   \n",
       "14              0.867153           0.015736  -0.050429  0.023055   \n",
       "15              0.957527           0.007545  -0.154400  0.020443   \n",
       "16              0.867698           0.017306  -0.065680  0.024038   \n",
       "17              0.820102           0.016977  -0.017604  0.023230   \n",
       "18              0.807611           0.018193  -0.005309  0.025009   \n",
       "19              0.821222           0.018126  -0.018709  0.026429   \n",
       "20              0.867476           0.015566  -0.065171  0.021902   \n",
       "21              0.957364           0.008992  -0.155193  0.020190   \n",
       "22              0.867909           0.018669  -0.046171  0.024841   \n",
       "23              0.819196           0.017066   0.002280  0.022083   \n",
       "24              0.807418           0.018367   0.013993  0.021823   \n",
       "25              0.821927           0.017667  -0.000960  0.023123   \n",
       "26              0.867764           0.016055  -0.046215  0.020517   \n",
       "27              0.957469           0.008621  -0.136524  0.016262   \n",
       "28              0.819382           0.017107   0.051189  0.020137   \n",
       "29              0.806091           0.018966   0.064560  0.022623   \n",
       "..                   ...                ...        ...       ...   \n",
       "118             0.803345           0.052719   0.065451  0.056337   \n",
       "119             0.826036           0.055475   0.042630  0.058829   \n",
       "120             0.955418           0.032850  -0.136536  0.035754   \n",
       "121             0.860727           0.050146  -0.042063  0.049727   \n",
       "122             0.812800           0.061486   0.006216  0.062455   \n",
       "123             0.805964           0.054168   0.012928  0.056615   \n",
       "124             0.822291           0.058877  -0.003594  0.060920   \n",
       "125             0.868000           0.040308  -0.049102  0.039364   \n",
       "126             0.953055           0.033242  -0.148128  0.034649   \n",
       "127             0.857418           0.053849  -0.052551  0.055117   \n",
       "128             0.812982           0.062184  -0.008220  0.061155   \n",
       "129             0.808800           0.053344  -0.003858  0.054325   \n",
       "130             0.822509           0.058271  -0.017374  0.059001   \n",
       "131             0.868400           0.037943  -0.063516  0.040060   \n",
       "132             0.950036           0.027335  -0.145414  0.033881   \n",
       "133             0.856691           0.054868  -0.034957  0.058423   \n",
       "134             0.811200           0.060403   0.010597  0.062426   \n",
       "135             0.806582           0.053806   0.015152  0.053739   \n",
       "136             0.825891           0.056635  -0.004482  0.056440   \n",
       "137             0.868364           0.041885  -0.046670  0.044226   \n",
       "138             0.951236           0.026903  -0.129590  0.031373   \n",
       "139             0.812436           0.057307   0.056128  0.059215   \n",
       "140             0.804182           0.053011   0.064653  0.052764   \n",
       "141             0.824691           0.058436   0.043500  0.059212   \n",
       "142             0.869164           0.041787  -0.000394  0.042524   \n",
       "143             0.952073           0.027838  -0.083355  0.029368   \n",
       "144             0.804691           0.049439   0.152287  0.049036   \n",
       "145             0.810945           0.061967   0.145600  0.062990   \n",
       "146             0.848073           0.047221   0.107355  0.046632   \n",
       "147             0.954727           0.025561  -0.000811  0.025282   \n",
       "\n",
       "     Possible Accuracy  \n",
       "0             0.929423  \n",
       "1             0.888878  \n",
       "2             0.871093  \n",
       "3             0.866886  \n",
       "4             0.889964  \n",
       "5             0.849571  \n",
       "6             0.831695  \n",
       "7             0.827573  \n",
       "8             0.832606  \n",
       "9             0.871900  \n",
       "10            0.831505  \n",
       "11            0.813672  \n",
       "12            0.809535  \n",
       "13            0.814610  \n",
       "14            0.832027  \n",
       "15            0.866807  \n",
       "16            0.826414  \n",
       "17            0.808555  \n",
       "18            0.804405  \n",
       "19            0.809538  \n",
       "20            0.826904  \n",
       "21            0.866288  \n",
       "22            0.833136  \n",
       "23            0.815345  \n",
       "24            0.811192  \n",
       "25            0.816262  \n",
       "26            0.833692  \n",
       "27            0.873056  \n",
       "28            0.831808  \n",
       "29            0.827676  \n",
       "..                 ...  \n",
       "118           0.847469  \n",
       "119           0.848032  \n",
       "120           0.819450  \n",
       "121           0.815357  \n",
       "122           0.813634  \n",
       "123           0.813218  \n",
       "124           0.813806  \n",
       "125           0.815823  \n",
       "126           0.810679  \n",
       "127           0.806505  \n",
       "128           0.804864  \n",
       "129           0.804396  \n",
       "130           0.805000  \n",
       "131           0.807033  \n",
       "132           0.810795  \n",
       "133           0.817813  \n",
       "134           0.816127  \n",
       "135           0.815677  \n",
       "136           0.816242  \n",
       "137           0.818310  \n",
       "138           0.822079  \n",
       "139           0.848035  \n",
       "140           0.847607  \n",
       "141           0.848185  \n",
       "142           0.850227  \n",
       "143           0.853997  \n",
       "144           0.923392  \n",
       "145           0.923985  \n",
       "146           0.926010  \n",
       "147           0.929782  \n",
       "\n",
       "[148 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 2: T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_equalratio=data[data['Ratio_Men']==0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_acmen_sd=data_equalratio.loc[:,\"Accuracy Men\"].std()\n",
    "h1_acmen_mean=data_equalratio.loc[:,\"Accuracy Men\"].mean()\n",
    "h1_acwomen_sd=data_equalratio.loc[:,\"Accuracy Women\"].std()\n",
    "h1_acwomen_mean=data_equalratio.loc[:,\"Accuracy Women\"].mean()\n",
    "h1_nobs=int(len(data_equalratio)/2)\n",
    "h1_bias_ds=data_equalratio.loc[:,\"Bias\"].std()\n",
    "h1_bias_mean=data_equalratio.loc[:,\"Bias\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsmodels.stats.weightstats.ttost_ind(data_equalratio['Accuracy Men'], data_equalratio['Accuracy Women'], -0.0116, 0.0116, usevar='pooled', weights=(None, None), transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1: TOST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nodiff=data[data['Difference_Probabilities']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsmodels.stats.weightstats.ttost_ind(data_nodiff['Accuracy Men'], data_nodiff['Accuracy Women'], -0.0116, 0.0116, usevar='pooled', weights=(None, None), transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(plot,difference,ratiomen,probmen,classifier):\n",
    "    \n",
    "    if classifier==\"SVM\":\n",
    "        datap=data\n",
    "    else:\n",
    "        if classifier==\"Naive Bayes\":\n",
    "            datap=data_nb\n",
    "        else:\n",
    "            datap=data_tree\n",
    "            \n",
    "    datap=datap[datap['Ratio_Men'].astype(str)==ratiomen]\n",
    "           \n",
    "    if plot=='Prob_Men':\n",
    "        datap=datap[datap['Difference_Probabilities'].astype(str)==difference]\n",
    "        fig = px.box(datap, x=\"Probability_Men\", y=\"Bias\",title=\"Bias dependent on Probability Men\")\n",
    "        fig.show()\n",
    "        \n",
    "    if plot=='Diff':\n",
    "        datap=datap[datap['Probability_Men'].astype(str)==probmen]\n",
    "        fig = px.box(datap, x=\"Difference_Probabilities\", y=\"Bias\",title=\"Bias dependent on Difference\")\n",
    "        fig.show()\n",
    "        \n",
    "    if plot=='Prob_MenxDiff':\n",
    "        fig = px.box(datap, x=\"Probability_Men\", color=\"Difference_Probabilities\",y=\"Bias\",title=\"Bias dependent on Probability Men and the Probabilities' Difference\")\n",
    "        fig.show()\n",
    "    \n",
    "    if plot=='DiffxProb_Men':\n",
    "        fig = px.box(datap, x=\"Difference_Probabilities\", color=\"Probability_Men\",y=\"Bias\",title=\"Bias dependent on Probability Men and the Probabilities' Difference\")\n",
    "        fig.show()\n",
    "    \n",
    "    if plot=='Prob_MenxAbsoluteDiff':\n",
    "        fig = px.box(datap, x=\"Probability_Men\", color=\"Absolute Difference\",y=\"Bias\",title=\"Bias dependent on Probability Men and the Probabilities' absolute Difference\")\n",
    "        fig.show()\n",
    "        \n",
    "    if plot=='Prob_MenxAbsoluteDiffXAbsBias':\n",
    "        fig = px.box(datap, x=\"Probability_Men\", color=\"Absolute Difference\",y=\"Absolute Bias\",title=\"Absolute Bias dependent on Probability Men and the Probabilities' absolute Difference\")\n",
    "        fig.show()\n",
    "    \n",
    "    return classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(p,plot=['Prob_Men','Diff','Prob_MenxDiff','DiffxProb_Men','Prob_MenxAbsoluteDiff','Prob_MenxAbsoluteDiffXAbsBias'],difference=['-0.45','-0.3','-0.15','0.00','0.15','0.3','0.45'],ratiomen=['0.50','0.65','0.80','0.95'],probmen=['0.05','0.20','0.35','0.50','0.65','0.80','0.95'],classifier=['SVM','Naive Bayes','Tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotexplorer(plot,difference,ratiomen,probmen,classifier):\n",
    "    \n",
    "    if classifier==\"SVM\":\n",
    "        datap=data\n",
    "    else:\n",
    "        if classifier==\"Naive Bayes\":\n",
    "            datap=data_nb\n",
    "        else:\n",
    "            datap=data_tree\n",
    "            \n",
    "    datap=datap[datap['Ratio_Men'].astype(str)==ratiomen]\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(13,10))\n",
    "    \n",
    "    if plot=='Prob_Men':\n",
    "        datap=datap[datap['Difference_Probabilities'].astype(str)==difference]\n",
    "        ax1 = sns.boxplot(x=\"Probability_Men\", y=\"Bias\",data=datap,width=0.8)\n",
    "        ax1.set(ylim=(-0.3,0.3))\n",
    "        ax1       \n",
    "        \n",
    "    if plot=='Diff':\n",
    "        datap=datap[datap['Probability_Men'].astype(str)==probmen]\n",
    "        ax1 = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=datap,width=0.8)\n",
    "        ax1.set(ylim=(-0.3,0.3))\n",
    "        ax1\n",
    "\n",
    "    if plot=='Info_Diff':\n",
    "        datap=datap[datap['Difference_Probabilities'].astype(str)==difference]\n",
    "        datap=datap[datap['Probability_Men'].astype(str)==probmen]\n",
    "        ax1 = sns.boxplot(x=\"Infomativeness_Difference\", y=\"Bias\",data=datap,width=0.8)\n",
    "        ax1.set(ylim=(-0.3,0.3))\n",
    "        ax1\n",
    "    \n",
    "    if plot=='Info_DiffxDiff':\n",
    "        ax1 = sns.boxplot(x=\"Infomativeness_Difference\", hue=\"Informativeness Men\",y=\"Bias\",data=datap,width=0.8)\n",
    "        ax1.set(ylim=(-0.3,0.3))\n",
    "        ax1\n",
    "    \n",
    "    if plot=='Prob_MenxDiff':\n",
    "        ax1 = sns.boxplot(x=\"Probability_Men\", hue=\"Difference_Probabilities\", y=\"Bias\",data=datap,width=0.8)\n",
    "        ax1.set(ylim=(-0.3,0.3))\n",
    "        ax1\n",
    "           \n",
    "    if plot=='DiffxProb_Men':\n",
    "        ax1 = sns.boxplot(x=\"Difference_Probabilities\", hue=\"Probability_Men\", y=\"Bias\",data=datap,width=0.8)\n",
    "        ax1.set(ylim=(-0.3,0.3))\n",
    "        ax1\n",
    "        \n",
    "\n",
    "    \n",
    "    return classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plotexplorer,plot=['Prob_Men','Diff','Info_Diff','Info_DiffxDiff','Prob_MenxDiff','DiffxProb_Men'],difference=['-0.45','-0.30','-0.15','0.00','0.15','0.30','0.45'],ratiomen=['0.50','0.65','0.80','0.95'],probmen=['0.05','0.20','0.35','0.50','0.65','0.80','0.95'],classifier=['SVM','Naive Bayes','Tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotcomparer(probdiff,ratiomen,classifier):\n",
    "    \n",
    "    if classifier==\"SVM\":\n",
    "        datap=data\n",
    "        datar=data\n",
    "    else:\n",
    "        if classifier==\"Naive Bayes\":\n",
    "            datap=data_nb\n",
    "            datar=data_nb\n",
    "        else:\n",
    "            datap=data_tree\n",
    "            datar=data_tree\n",
    "            \n",
    "    datap=datap[datap['Ratio_Men'].astype(str)==ratiomen]\n",
    "    datar=datar[datar['Ratio_Men'].astype(str)==ratiomen]\n",
    "    datap=datap[datap['Difference_Probabilities'].astype(str)==probdiff]\n",
    "    datar=datar[datar['Difference_Probabilities'].astype(str)==\"0.00\"]\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(8,7))\n",
    "    \n",
    "    \n",
    "    ax2 = sns.boxplot(x=\"Probability_Men\", y=\"Bias\",data=datar,width=0.8)\n",
    "    ax2.set_title('Reference Plot')\n",
    "    ax2.set(ylim=(-0.3,0.3))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,7))\n",
    "    ax = sns.boxplot(x=\"Probability_Men\", y=\"Bias\",data=datap,width=0.8)\n",
    "    ax.set(ylim=(-0.3,0.3))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plotcomparer,\n",
    "         probdiff=['-0.45','-0.30','-0.15','0.00','0.15','0.30','0.45'],\n",
    "         ratiomen=['0.50','0.65','0.80','0.95'],\n",
    "         classifier=['SVM','Naive Bayes','Tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with 50% Mens Ratio in Sample\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_50,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis2.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with 65% Mens Ratio in Sample\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_65,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis2_65.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with 80% Mens Ratio in Sample\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_80,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis2_80.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with 95% Mens Ratio in Sample\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_95,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis2_95.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with Probability Differnce of Men and Women = 0\" )\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_d00,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of Probability Differences between Men an Women on Bias\")\n",
    "ax = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=data,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Interaction Effects of the Mens Informativeness and the Womens Informativeness on the Bias\")\n",
    "ax = sns.boxplot(x=\"Informativeness Men\", hue=\"Informativeness Women\",y=\"Bias\",data=data,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"infmenvsinfwomen.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs for Fixed Probability Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5=data[data['Probability_Men'].astype(str)==\"0.05\"]\n",
    "data20=data[data['Probability_Men'].astype(str)==\"0.20\"]\n",
    "data35=data[data['Probability_Men'].astype(str)==\"0.35\"]\n",
    "data50=data[data['Probability_Men'].astype(str)==\"0.50\"]\n",
    "data65=data[data['Probability_Men'].astype(str)==\"0.65\"]\n",
    "data80=data[data['Probability_Men'].astype(str)==\"0.80\"]\n",
    "data95=data[data['Probability_Men'].astype(str)==\"0.95\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the Mens Sample Ratio on Bias [Fixed Probability of 0.05]\")\n",
    "ax = sns.boxplot(x=\"Ratio_Men\", y=\"Bias\",data=data5,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p05_ratio.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Probability Differences of Men an Women on Bias [Fixed Probability of 0.05]\")\n",
    "ax = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=data5,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p05_diff.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Informativeness Differences of Men an Women on Bias [Fixed Probability of 0.05]\")\n",
    "ax = sns.boxplot(x=\"Infomativeness_Difference\", y=\"Bias\",data=data5,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p05_infdiff.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Men = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the Mens Sample Ratio on Bias [Fixed Probability of 0.20]\")\n",
    "ax = sns.boxplot(x=\"Ratio_Men\", y=\"Bias\",data=data20,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p20_ratio.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Probability Differences of Men an Women on Bias [Fixed Probability of 0.20]\")\n",
    "ax = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=data20,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p20_diff.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Informativeness Differences of Men an Women on Bias [Fixed Probability of 0.20]\")\n",
    "ax = sns.boxplot(x=\"Infomativeness_Difference\", y=\"Bias\",data=data20,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p20_infdiff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the Mens Sample Ratio on Bias [Fixed Probability of 0.35]\")\n",
    "ax = sns.boxplot(x=\"Ratio_Men\", y=\"Bias\",data=data35,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p35_ratio.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Probability Differences of Men an Women on Bias [Fixed Probability of 0.35]\")\n",
    "ax = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=data35,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p35_diff.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Informativeness Differences of Men an Women on Bias [Fixed Probability of 0.35]\")\n",
    "ax = sns.boxplot(x=\"Infomativeness_Difference\", y=\"Bias\",data=data35,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p35_infdiff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the Mens Sample Ratio on Bias [Fixed Probability of 0.50]\")\n",
    "ax = sns.boxplot(x=\"Ratio_Men\", y=\"Bias\",data=data50,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p50_ratio.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Probability Differences of Men an Women on Bias [Fixed Probability of 0.50]\")\n",
    "ax = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=data50,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p50_diff.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Informativeness Differences of Men an Women on Bias [Fixed Probability of 0.50]\")\n",
    "ax = sns.boxplot(x=\"Infomativeness_Difference\", y=\"Bias\",data=data50,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p50_infdiff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the Mens Sample Ratio on Bias [Fixed Probability of 0.65]\")\n",
    "ax = sns.boxplot(x=\"Ratio_Men\", y=\"Bias\",data=data65,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p65_ratio.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Probability Differences of Men an Women on Bias [Fixed Probability of 0.65]\")\n",
    "ax = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=data65,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p65_diff.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Informativeness Differences of Men an Women on Bias [Fixed Probability of 0.65]\")\n",
    "ax = sns.boxplot(x=\"Infomativeness_Difference\", y=\"Bias\",data=data65,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p65_infdiff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the Mens Sample Ratio on Bias [Fixed Probability of 0.80]\")\n",
    "ax = sns.boxplot(x=\"Ratio_Men\", y=\"Bias\",data=data80,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p80_ratio.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Probability Differences of Men an Women on Bias [Fixed Probability of 0.80]\")\n",
    "ax = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=data80,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p80_diff.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Informativeness Differences of Men an Women on Bias [Fixed Probability of 0.80]\")\n",
    "ax = sns.boxplot(x=\"Infomativeness_Difference\", y=\"Bias\",data=data80,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p80_infdiff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the Mens Sample Ratio on Bias [Fixed Probability of 0.95]\")\n",
    "ax = sns.boxplot(x=\"Ratio_Men\", y=\"Bias\",data=data95,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p95_ratio.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Probability Differences of Men an Women on Bias [Fixed Probability of 0.95]\")\n",
    "ax = sns.boxplot(x=\"Difference_Probabilities\", y=\"Bias\",data=data95,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p95_diff.png\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Main Effect of the the Informativeness Differences of Men an Women on Bias [Fixed Probability of 0.95]\")\n",
    "ax = sns.boxplot(x=\"Infomativeness_Difference\", y=\"Bias\",data=data95,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "\n",
    "ax.figure.savefig(\"p95_infdiff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Intervalls (~99.966%, resulting from Bonferroni-Correcture) for the Biases of the Experimental Groups.\n"
     ]
    }
   ],
   "source": [
    "confidence = 0.99966216216\n",
    "starts=[]\n",
    "means=[]\n",
    "sd=[]\n",
    "ends=[]\n",
    "groups=[]\n",
    "\n",
    "print(\"Confidence Intervalls (~99.966%, resulting from Bonferroni-Correcture) for the Biases of the Experimental Groups.\")\n",
    "\n",
    "for i in range(1,149):\n",
    "    datac = data[data['Exp. Group']==i]['Bias']\n",
    "    n = len(datac)\n",
    "    m = mean(datac)\n",
    "    std_err = sem(datac)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = m - h\n",
    "    end = m + h\n",
    "    starts.append(start)\n",
    "    means.append(m)\n",
    "    sd.append(std_err)\n",
    "    ends.append(end)\n",
    "    groups.append(i)\n",
    "    #print(\"For Exp. Group \" +str(i) + \" the Confidenceintervall is from \" + str(start) + \" to \" +str(end))\n",
    "    \n",
    "biasconf=pd.DataFrame({'Exp. Group' : groups,\n",
    "                                'Lower Bound Bias' : starts, 'Mean Bias':means,\n",
    "                                'Upper Bound Bias' : ends,'SD Bias':sd })\n",
    "\n",
    "starts=[]\n",
    "means=[]\n",
    "sd=[]\n",
    "ends=[]\n",
    "groups=[]\n",
    "\n",
    "for i in range(1,149):\n",
    "    datac = data_nosex[data_nosex['Exp. Group']==i]['Bias']\n",
    "    n = len(datac)\n",
    "    m = mean(datac)\n",
    "    std_err = sem(datac)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = m - h\n",
    "    end = m + h\n",
    "    starts.append(start)\n",
    "    means.append(m)\n",
    "    sd.append(std_err)\n",
    "    ends.append(end)\n",
    "    groups.append(i)\n",
    "    #print(\"For Exp. Group \" +str(i) + \" the Confidenceintervall is from \" + str(start) + \" to \" +str(end))\n",
    "    \n",
    "biasconf['Lower Bound NO SEX']=starts\n",
    "biasconf['Mean NO SEX']=means\n",
    "biasconf['Upper Bound NO SEX']=ends\n",
    "biasconf['SD NO SEX']=sd\n",
    "\n",
    "starts=[]\n",
    "means=[]\n",
    "sd=[]\n",
    "ends=[]\n",
    "groups=[]\n",
    "\n",
    "for i in range(1,149):\n",
    "    datac = data_nosexinf[data_nosexinf['Exp. Group']==i]['Bias']\n",
    "    n = len(datac)\n",
    "    m = mean(datac)\n",
    "    std_err = sem(datac)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = m - h\n",
    "    end = m + h\n",
    "    starts.append(start)\n",
    "    means.append(m)\n",
    "    sd.append(std_err)\n",
    "    ends.append(end)\n",
    "    groups.append(i)\n",
    "    #print(\"For Exp. Group \" +str(i) + \" the Confidenceintervall is from \" + str(start) + \" to \" +str(end))\n",
    "    \n",
    "biasconf['Lower Bound NO SEX INF']=starts\n",
    "biasconf['Mean NO SEX INF']=means\n",
    "biasconf['Upper Bound NO SEX INF']=ends\n",
    "biasconf['SD NO SEX INF']=sd\n",
    "#biasconf['Accuracy']=\n",
    "#biasconf['Possible Accuracy']=\n",
    "\n",
    "biasconf.to_csv(\"CI_Biases_EG_SDANDMEAN.csv\",sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Intervalls (~99.966%, resulting from Bonferroni-Correcture) for the Biases of the Experimental Groups.\n"
     ]
    }
   ],
   "source": [
    "confidence = 0.99966216216\n",
    "starts=[]\n",
    "means=[]\n",
    "ends=[]\n",
    "sd=[]\n",
    "groups=[]\n",
    "\n",
    "print(\"Confidence Intervalls (~99.966%, resulting from Bonferroni-Correcture) for the Biases of the Experimental Groups.\")\n",
    "\n",
    "for i in ('-0.45','-0.3','-0.15','0.0','0.15','0.3','0.45'):\n",
    "    datac = data[data['Infomativeness_Difference'].astype(str)==i]['Bias']\n",
    "    n = len(datac)\n",
    "    m = mean(datac)\n",
    "    std_err = sem(datac)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = m - h\n",
    "    end = m + h\n",
    "    starts.append(start)\n",
    "    means.append(m)\n",
    "    sd.append(std_err)\n",
    "    ends.append(end)\n",
    "    groups.append(i)\n",
    "    #print(\"For Exp. Group \" +str(i) + \" the Confidenceintervall is from \" + str(start) + \" to \" +str(end))\n",
    "    \n",
    "biasconfn=pd.DataFrame()\n",
    "biasconfn['Information Difference']=groups\n",
    "biasconfn['Lower Bound Bias']=starts\n",
    "biasconfn['Mean Bias']=means\n",
    "biasconfn['Upper Bound Bias']=ends\n",
    "biasconfn['SD Bias']=sd\n",
    "\n",
    "starts=[]\n",
    "means=[]\n",
    "ends=[]\n",
    "sd=[]\n",
    "for i in ('-0.45','-0.3','-0.15','0.0','0.15','0.3','0.45'):\n",
    "    datac = data_nosex[data_nosex['Infomativeness_Difference'].astype(str)==i]['Bias']\n",
    "    n = len(datac)\n",
    "    m = mean(datac)\n",
    "    std_err = sem(datac)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = m - h\n",
    "    end = m + h\n",
    "    starts.append(start)\n",
    "    means.append(m)\n",
    "    ends.append(end)\n",
    "    sd.append(std_err)\n",
    "\n",
    "biasconfn['Lower Bound No Sex']=starts\n",
    "biasconfn['Mean No Sex']=means\n",
    "biasconfn['Upper Bound No Sex']=ends\n",
    "biasconfn['SD No Sex']=sd\n",
    "\n",
    "starts=[]\n",
    "means=[]\n",
    "ends=[]\n",
    "sd=[]\n",
    "for i in ('-0.45','-0.3','-0.15','0.0','0.15','0.3','0.45'):\n",
    "    datac = data_nosexinf[data_nosexinf['Infomativeness_Difference'].astype(str)==i]['Bias']\n",
    "    n = len(datac)\n",
    "    m = mean(datac)\n",
    "    std_err = sem(datac)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = m - h\n",
    "    end = m + h\n",
    "    starts.append(start)\n",
    "    means.append(m)\n",
    "    ends.append(end)\n",
    "    sd.append(std_err)\n",
    "\n",
    "biasconfn['Lower Bound No Sex Inf']=starts\n",
    "biasconfn['Mean No Sex Inf']=means\n",
    "biasconfn['Upper Bound No Sex Inf']=ends\n",
    "biasconfn['SD No Sex Inf']=sd\n",
    "    \n",
    "biasconfn.to_csv(\"CI_Biases_InfDiff_SDANDMEAN.csv\",sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp. Group</th>\n",
       "      <th>Lower Bound Bias</th>\n",
       "      <th>Mean Bias</th>\n",
       "      <th>Upper Bound Bias</th>\n",
       "      <th>SD Bias</th>\n",
       "      <th>Lower Bound NO SEX</th>\n",
       "      <th>Mean NO SEX</th>\n",
       "      <th>Upper Bound NO SEX</th>\n",
       "      <th>SD NO SEX</th>\n",
       "      <th>Lower Bound NO SEX INF</th>\n",
       "      <th>Mean NO SEX INF</th>\n",
       "      <th>Upper Bound NO SEX INF</th>\n",
       "      <th>SD NO SEX INF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.088241</td>\n",
       "      <td>0.091444</td>\n",
       "      <td>0.094646</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.088706</td>\n",
       "      <td>0.091789</td>\n",
       "      <td>0.094872</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.087717</td>\n",
       "      <td>0.090891</td>\n",
       "      <td>0.094065</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.135427</td>\n",
       "      <td>0.138491</td>\n",
       "      <td>0.141554</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.133945</td>\n",
       "      <td>0.137215</td>\n",
       "      <td>0.140484</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.130164</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>0.136738</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.148038</td>\n",
       "      <td>0.151167</td>\n",
       "      <td>0.154296</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.146391</td>\n",
       "      <td>0.149596</td>\n",
       "      <td>0.152801</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.139889</td>\n",
       "      <td>0.143022</td>\n",
       "      <td>0.146155</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.091901</td>\n",
       "      <td>-0.089196</td>\n",
       "      <td>-0.086491</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>-0.092814</td>\n",
       "      <td>-0.089909</td>\n",
       "      <td>-0.087004</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>-0.091742</td>\n",
       "      <td>-0.088745</td>\n",
       "      <td>-0.085749</td>\n",
       "      <td>0.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.003699</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>-0.002442</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.044565</td>\n",
       "      <td>0.048149</td>\n",
       "      <td>0.051733</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.043413</td>\n",
       "      <td>0.046985</td>\n",
       "      <td>0.050558</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.044187</td>\n",
       "      <td>0.047858</td>\n",
       "      <td>0.051529</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.058345</td>\n",
       "      <td>0.062065</td>\n",
       "      <td>0.065786</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.058638</td>\n",
       "      <td>0.062545</td>\n",
       "      <td>0.066453</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>0.060793</td>\n",
       "      <td>0.064509</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.043619</td>\n",
       "      <td>0.047342</td>\n",
       "      <td>0.051065</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.042485</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>0.050213</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.039869</td>\n",
       "      <td>0.043589</td>\n",
       "      <td>0.047309</td>\n",
       "      <td>0.001031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.143827</td>\n",
       "      <td>-0.140745</td>\n",
       "      <td>-0.137664</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>-0.142659</td>\n",
       "      <td>-0.139538</td>\n",
       "      <td>-0.136417</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>-0.140698</td>\n",
       "      <td>-0.137225</td>\n",
       "      <td>-0.133753</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.054650</td>\n",
       "      <td>-0.051265</td>\n",
       "      <td>-0.047881</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.053569</td>\n",
       "      <td>-0.050196</td>\n",
       "      <td>-0.046824</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>-0.053197</td>\n",
       "      <td>-0.049582</td>\n",
       "      <td>-0.045967</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.006763</td>\n",
       "      <td>-0.003287</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>-0.007619</td>\n",
       "      <td>-0.003978</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>-0.007054</td>\n",
       "      <td>-0.003535</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>0.013844</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.016159</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.008998</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.009293</td>\n",
       "      <td>-0.005102</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>-0.008176</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.053975</td>\n",
       "      <td>-0.050429</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>-0.054303</td>\n",
       "      <td>-0.050549</td>\n",
       "      <td>-0.046796</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>-0.050837</td>\n",
       "      <td>-0.047015</td>\n",
       "      <td>-0.043192</td>\n",
       "      <td>0.001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.157544</td>\n",
       "      <td>-0.154400</td>\n",
       "      <td>-0.151256</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>-0.155117</td>\n",
       "      <td>-0.151600</td>\n",
       "      <td>-0.148083</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>-0.148334</td>\n",
       "      <td>-0.145004</td>\n",
       "      <td>-0.141673</td>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.069377</td>\n",
       "      <td>-0.065680</td>\n",
       "      <td>-0.061983</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>-0.068328</td>\n",
       "      <td>-0.064455</td>\n",
       "      <td>-0.060581</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>-0.065478</td>\n",
       "      <td>-0.061676</td>\n",
       "      <td>-0.057875</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.021177</td>\n",
       "      <td>-0.017604</td>\n",
       "      <td>-0.014031</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>-0.020994</td>\n",
       "      <td>-0.017342</td>\n",
       "      <td>-0.013689</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>-0.021442</td>\n",
       "      <td>-0.017858</td>\n",
       "      <td>-0.014275</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.009156</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>-0.009378</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.010727</td>\n",
       "      <td>-0.006709</td>\n",
       "      <td>-0.002691</td>\n",
       "      <td>0.001114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.018709</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>-0.023689</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>-0.015839</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>-0.023484</td>\n",
       "      <td>-0.019716</td>\n",
       "      <td>-0.015949</td>\n",
       "      <td>0.001044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.068540</td>\n",
       "      <td>-0.065171</td>\n",
       "      <td>-0.061802</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.068805</td>\n",
       "      <td>-0.065164</td>\n",
       "      <td>-0.061523</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>-0.068532</td>\n",
       "      <td>-0.064865</td>\n",
       "      <td>-0.061199</td>\n",
       "      <td>0.001016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.158298</td>\n",
       "      <td>-0.155193</td>\n",
       "      <td>-0.152087</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>-0.157157</td>\n",
       "      <td>-0.154065</td>\n",
       "      <td>-0.150974</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>-0.149431</td>\n",
       "      <td>-0.146058</td>\n",
       "      <td>-0.142685</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.049992</td>\n",
       "      <td>-0.046171</td>\n",
       "      <td>-0.042350</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>-0.051870</td>\n",
       "      <td>-0.048058</td>\n",
       "      <td>-0.044246</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.048340</td>\n",
       "      <td>-0.044298</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>0.001121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.001117</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.001083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>0.017349</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.013305</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.009746</td>\n",
       "      <td>0.013236</td>\n",
       "      <td>0.016727</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.004835</td>\n",
       "      <td>-0.001225</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.005437</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.049370</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>-0.043059</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>-0.048655</td>\n",
       "      <td>-0.045473</td>\n",
       "      <td>-0.042290</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>-0.049138</td>\n",
       "      <td>-0.045927</td>\n",
       "      <td>-0.042716</td>\n",
       "      <td>0.000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.139025</td>\n",
       "      <td>-0.136524</td>\n",
       "      <td>-0.134022</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>-0.138165</td>\n",
       "      <td>-0.135520</td>\n",
       "      <td>-0.132875</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>-0.135087</td>\n",
       "      <td>-0.132287</td>\n",
       "      <td>-0.129488</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.048092</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.043933</td>\n",
       "      <td>0.046876</td>\n",
       "      <td>0.049819</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.044520</td>\n",
       "      <td>0.047513</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.061080</td>\n",
       "      <td>0.064560</td>\n",
       "      <td>0.068040</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.058722</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.066173</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.061040</td>\n",
       "      <td>0.064607</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>0.074116</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.072994</td>\n",
       "      <td>0.082153</td>\n",
       "      <td>0.091312</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.077743</td>\n",
       "      <td>0.087416</td>\n",
       "      <td>0.097089</td>\n",
       "      <td>0.002682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.042630</td>\n",
       "      <td>0.051678</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.068451</td>\n",
       "      <td>0.078212</td>\n",
       "      <td>0.087974</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.086303</td>\n",
       "      <td>0.096232</td>\n",
       "      <td>0.106160</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121</td>\n",
       "      <td>-0.142035</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.131037</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>-0.127327</td>\n",
       "      <td>-0.121248</td>\n",
       "      <td>-0.115169</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>-0.125908</td>\n",
       "      <td>-0.119778</td>\n",
       "      <td>-0.113648</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122</td>\n",
       "      <td>-0.049712</td>\n",
       "      <td>-0.042063</td>\n",
       "      <td>-0.034415</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>-0.051430</td>\n",
       "      <td>-0.043581</td>\n",
       "      <td>-0.035731</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>-0.049068</td>\n",
       "      <td>-0.041146</td>\n",
       "      <td>-0.033225</td>\n",
       "      <td>0.002196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>123</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>-0.007656</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>-0.009636</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.002644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>124</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.012928</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.014394</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.002486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>125</td>\n",
       "      <td>-0.012964</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>-0.003831</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.010142</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>0.002433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>126</td>\n",
       "      <td>-0.055157</td>\n",
       "      <td>-0.049102</td>\n",
       "      <td>-0.043048</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>-0.029267</td>\n",
       "      <td>-0.022048</td>\n",
       "      <td>-0.014829</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>-0.021484</td>\n",
       "      <td>-0.014366</td>\n",
       "      <td>-0.007247</td>\n",
       "      <td>0.001973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>-0.153458</td>\n",
       "      <td>-0.148128</td>\n",
       "      <td>-0.142799</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>-0.128584</td>\n",
       "      <td>-0.122233</td>\n",
       "      <td>-0.115883</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>-0.126580</td>\n",
       "      <td>-0.120212</td>\n",
       "      <td>-0.113845</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>-0.061029</td>\n",
       "      <td>-0.052551</td>\n",
       "      <td>-0.044074</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>-0.055641</td>\n",
       "      <td>-0.047238</td>\n",
       "      <td>-0.038836</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>-0.051644</td>\n",
       "      <td>-0.043581</td>\n",
       "      <td>-0.035518</td>\n",
       "      <td>0.002235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>-0.017626</td>\n",
       "      <td>-0.008220</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>-0.020592</td>\n",
       "      <td>-0.010549</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>-0.021848</td>\n",
       "      <td>-0.012052</td>\n",
       "      <td>-0.002255</td>\n",
       "      <td>0.002716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130</td>\n",
       "      <td>-0.012214</td>\n",
       "      <td>-0.003858</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>-0.011609</td>\n",
       "      <td>-0.004103</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>-0.012124</td>\n",
       "      <td>-0.003805</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131</td>\n",
       "      <td>-0.026449</td>\n",
       "      <td>-0.017374</td>\n",
       "      <td>-0.008299</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>-0.027697</td>\n",
       "      <td>-0.019979</td>\n",
       "      <td>-0.012260</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>-0.027954</td>\n",
       "      <td>-0.020247</td>\n",
       "      <td>-0.012540</td>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132</td>\n",
       "      <td>-0.069677</td>\n",
       "      <td>-0.063516</td>\n",
       "      <td>-0.057354</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>-0.062717</td>\n",
       "      <td>-0.055321</td>\n",
       "      <td>-0.047924</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>-0.059989</td>\n",
       "      <td>-0.052999</td>\n",
       "      <td>-0.046009</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133</td>\n",
       "      <td>-0.150626</td>\n",
       "      <td>-0.145414</td>\n",
       "      <td>-0.140203</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>-0.128695</td>\n",
       "      <td>-0.122433</td>\n",
       "      <td>-0.116171</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>-0.122616</td>\n",
       "      <td>-0.116859</td>\n",
       "      <td>-0.111102</td>\n",
       "      <td>0.001596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>-0.043943</td>\n",
       "      <td>-0.034957</td>\n",
       "      <td>-0.025971</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>-0.027353</td>\n",
       "      <td>-0.017730</td>\n",
       "      <td>-0.008108</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>-0.017975</td>\n",
       "      <td>-0.008446</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.002642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>135</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.020199</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.016984</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>0.028265</td>\n",
       "      <td>0.002783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.023418</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.020609</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>0.020777</td>\n",
       "      <td>0.001987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.004482</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>-0.012448</td>\n",
       "      <td>-0.004415</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>-0.015839</td>\n",
       "      <td>-0.007478</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.002318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>-0.053472</td>\n",
       "      <td>-0.046670</td>\n",
       "      <td>-0.039867</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>-0.053458</td>\n",
       "      <td>-0.046356</td>\n",
       "      <td>-0.039254</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>-0.051494</td>\n",
       "      <td>-0.044459</td>\n",
       "      <td>-0.037424</td>\n",
       "      <td>0.001950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>-0.134416</td>\n",
       "      <td>-0.129590</td>\n",
       "      <td>-0.124765</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>-0.122071</td>\n",
       "      <td>-0.116710</td>\n",
       "      <td>-0.111350</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>-0.121233</td>\n",
       "      <td>-0.115761</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>0.001517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>0.047020</td>\n",
       "      <td>0.056128</td>\n",
       "      <td>0.065236</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.073140</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.095460</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.091802</td>\n",
       "      <td>0.101669</td>\n",
       "      <td>0.111536</td>\n",
       "      <td>0.002735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>0.056537</td>\n",
       "      <td>0.064653</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.063547</td>\n",
       "      <td>0.071799</td>\n",
       "      <td>0.080051</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.070489</td>\n",
       "      <td>0.079125</td>\n",
       "      <td>0.087762</td>\n",
       "      <td>0.002394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142</td>\n",
       "      <td>0.034393</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.052608</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.038645</td>\n",
       "      <td>0.047688</td>\n",
       "      <td>0.056731</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.040525</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.057802</td>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143</td>\n",
       "      <td>-0.006935</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>-0.006590</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>-0.006332</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144</td>\n",
       "      <td>-0.087872</td>\n",
       "      <td>-0.083355</td>\n",
       "      <td>-0.078838</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>-0.085954</td>\n",
       "      <td>-0.081104</td>\n",
       "      <td>-0.076254</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>-0.085101</td>\n",
       "      <td>-0.080295</td>\n",
       "      <td>-0.075488</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>145</td>\n",
       "      <td>0.144745</td>\n",
       "      <td>0.152287</td>\n",
       "      <td>0.159829</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.187035</td>\n",
       "      <td>0.196777</td>\n",
       "      <td>0.206519</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.222472</td>\n",
       "      <td>0.235571</td>\n",
       "      <td>0.248670</td>\n",
       "      <td>0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>0.135912</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.155288</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.162102</td>\n",
       "      <td>0.173269</td>\n",
       "      <td>0.184436</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.183869</td>\n",
       "      <td>0.194626</td>\n",
       "      <td>0.205383</td>\n",
       "      <td>0.002982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>0.100183</td>\n",
       "      <td>0.107355</td>\n",
       "      <td>0.114527</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.112395</td>\n",
       "      <td>0.120059</td>\n",
       "      <td>0.127724</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.123740</td>\n",
       "      <td>0.130887</td>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>-0.004700</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>-0.005455</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>-0.004071</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.001064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Exp. Group  Lower Bound Bias  Mean Bias  Upper Bound Bias   SD Bias  \\\n",
       "0             1          0.000063   0.001924          0.003784  0.000516   \n",
       "1             2          0.088241   0.091444          0.094646  0.000888   \n",
       "2             3          0.135427   0.138491          0.141554  0.000849   \n",
       "3             4          0.148038   0.151167          0.154296  0.000867   \n",
       "4             5         -0.091901  -0.089196         -0.086491  0.000750   \n",
       "5             6         -0.003699  -0.000265          0.003168  0.000952   \n",
       "6             7          0.044565   0.048149          0.051733  0.000994   \n",
       "7             8          0.058345   0.062065          0.065786  0.001031   \n",
       "8             9          0.043619   0.047342          0.051065  0.001032   \n",
       "9            10         -0.143827  -0.140745         -0.137664  0.000854   \n",
       "10           11         -0.054650  -0.051265         -0.047881  0.000938   \n",
       "11           12         -0.006763  -0.003287          0.000188  0.000964   \n",
       "12           13          0.005603   0.009724          0.013844  0.001142   \n",
       "13           14         -0.008998  -0.004815         -0.000631  0.001160   \n",
       "14           15         -0.053975  -0.050429         -0.046883  0.000983   \n",
       "15           16         -0.157544  -0.154400         -0.151256  0.000872   \n",
       "16           17         -0.069377  -0.065680         -0.061983  0.001025   \n",
       "17           18         -0.021177  -0.017604         -0.014031  0.000991   \n",
       "18           19         -0.009156  -0.005309         -0.001463  0.001066   \n",
       "19           20         -0.022774  -0.018709         -0.014644  0.001127   \n",
       "20           21         -0.068540  -0.065171         -0.061802  0.000934   \n",
       "21           22         -0.158298  -0.155193         -0.152087  0.000861   \n",
       "22           23         -0.049992  -0.046171         -0.042350  0.001059   \n",
       "23           24         -0.001117   0.002280          0.005677  0.000942   \n",
       "24           25          0.010636   0.013993          0.017349  0.000931   \n",
       "25           26         -0.004517  -0.000960          0.002597  0.000986   \n",
       "26           27         -0.049370  -0.046215         -0.043059  0.000875   \n",
       "27           28         -0.139025  -0.136524         -0.134022  0.000693   \n",
       "28           29          0.048092   0.051189          0.054286  0.000859   \n",
       "29           30          0.061080   0.064560          0.068040  0.000965   \n",
       "..          ...               ...        ...               ...       ...   \n",
       "118         119          0.056786   0.065451          0.074116  0.002402   \n",
       "119         120          0.033581   0.042630          0.051678  0.002508   \n",
       "120         121         -0.142035  -0.136536         -0.131037  0.001525   \n",
       "121         122         -0.049712  -0.042063         -0.034415  0.002120   \n",
       "122         123         -0.003390   0.006216          0.015822  0.002663   \n",
       "123         124          0.004220   0.012928          0.021636  0.002414   \n",
       "124         125         -0.012964  -0.003594          0.005776  0.002598   \n",
       "125         126         -0.055157  -0.049102         -0.043048  0.001678   \n",
       "126         127         -0.153458  -0.148128         -0.142799  0.001477   \n",
       "127         128         -0.061029  -0.052551         -0.044074  0.002350   \n",
       "128         129         -0.017626  -0.008220          0.001186  0.002608   \n",
       "129         130         -0.012214  -0.003858          0.004497  0.002316   \n",
       "130         131         -0.026449  -0.017374         -0.008299  0.002516   \n",
       "131         132         -0.069677  -0.063516         -0.057354  0.001708   \n",
       "132         133         -0.150626  -0.145414         -0.140203  0.001445   \n",
       "133         134         -0.043943  -0.034957         -0.025971  0.002491   \n",
       "134         135          0.000995   0.010597          0.020199  0.002662   \n",
       "135         136          0.006887   0.015152          0.023418  0.002291   \n",
       "136         137         -0.013163  -0.004482          0.004199  0.002407   \n",
       "137         138         -0.053472  -0.046670         -0.039867  0.001886   \n",
       "138         139         -0.134416  -0.129590         -0.124765  0.001338   \n",
       "139         140          0.047020   0.056128          0.065236  0.002525   \n",
       "140         141          0.056537   0.064653          0.072768  0.002250   \n",
       "141         142          0.034393   0.043500          0.052608  0.002525   \n",
       "142         143         -0.006935  -0.000394          0.006146  0.001813   \n",
       "143         144         -0.087872  -0.083355         -0.078838  0.001252   \n",
       "144         145          0.144745   0.152287          0.159829  0.002091   \n",
       "145         146          0.135912   0.145600          0.155288  0.002686   \n",
       "146         147          0.100183   0.107355          0.114527  0.001988   \n",
       "147         148         -0.004700  -0.000811          0.003077  0.001078   \n",
       "\n",
       "     Lower Bound NO SEX  Mean NO SEX  Upper Bound NO SEX  SD NO SEX  \\\n",
       "0              0.000575     0.002436            0.004298   0.000516   \n",
       "1              0.088706     0.091789            0.094872   0.000855   \n",
       "2              0.133945     0.137215            0.140484   0.000906   \n",
       "3              0.146391     0.149596            0.152801   0.000888   \n",
       "4             -0.092814    -0.089909           -0.087004   0.000805   \n",
       "5             -0.002778     0.000527            0.003833   0.000916   \n",
       "6              0.043413     0.046985            0.050558   0.000990   \n",
       "7              0.058638     0.062545            0.066453   0.001083   \n",
       "8              0.042485     0.046349            0.050213   0.001071   \n",
       "9             -0.142659    -0.139538           -0.136417   0.000865   \n",
       "10            -0.053569    -0.050196           -0.046824   0.000935   \n",
       "11            -0.007619    -0.003978           -0.000337   0.001009   \n",
       "12             0.008016     0.012087            0.016159   0.001129   \n",
       "13            -0.009293    -0.005102           -0.000910   0.001162   \n",
       "14            -0.054303    -0.050549           -0.046796   0.001041   \n",
       "15            -0.155117    -0.151600           -0.148083   0.000975   \n",
       "16            -0.068328    -0.064455           -0.060581   0.001074   \n",
       "17            -0.020994    -0.017342           -0.013689   0.001013   \n",
       "18            -0.009378    -0.005484           -0.001589   0.001080   \n",
       "19            -0.023689    -0.019764           -0.015839   0.001088   \n",
       "20            -0.068805    -0.065164           -0.061523   0.001009   \n",
       "21            -0.157157    -0.154065           -0.150974   0.000857   \n",
       "22            -0.051870    -0.048058           -0.044246   0.001057   \n",
       "23            -0.003395     0.000356            0.004108   0.001040   \n",
       "24             0.009867     0.013305            0.016744   0.000953   \n",
       "25            -0.004835    -0.001225            0.002384   0.001001   \n",
       "26            -0.048655    -0.045473           -0.042290   0.000882   \n",
       "27            -0.138165    -0.135520           -0.132875   0.000733   \n",
       "28             0.043933     0.046876            0.049819   0.000816   \n",
       "29             0.058722     0.062447            0.066173   0.001033   \n",
       "..                  ...          ...                 ...        ...   \n",
       "118            0.072994     0.082153            0.091312   0.002539   \n",
       "119            0.068451     0.078212            0.087974   0.002706   \n",
       "120           -0.127327    -0.121248           -0.115169   0.001685   \n",
       "121           -0.051430    -0.043581           -0.035731   0.002176   \n",
       "122           -0.007656     0.001359            0.010374   0.002499   \n",
       "123            0.009310     0.018220            0.027130   0.002470   \n",
       "124           -0.003831     0.005380            0.014591   0.002554   \n",
       "125           -0.029267    -0.022048           -0.014829   0.002001   \n",
       "126           -0.128584    -0.122233           -0.115883   0.001761   \n",
       "127           -0.055641    -0.047238           -0.038836   0.002329   \n",
       "128           -0.020592    -0.010549           -0.000506   0.002784   \n",
       "129           -0.011609    -0.004103            0.003403   0.002081   \n",
       "130           -0.027697    -0.019979           -0.012260   0.002140   \n",
       "131           -0.062717    -0.055321           -0.047924   0.002051   \n",
       "132           -0.128695    -0.122433           -0.116171   0.001736   \n",
       "133           -0.027353    -0.017730           -0.008108   0.002668   \n",
       "134            0.006990     0.016984            0.026977   0.002770   \n",
       "135            0.006247     0.013428            0.020609   0.001991   \n",
       "136           -0.012448    -0.004415            0.003617   0.002227   \n",
       "137           -0.053458    -0.046356           -0.039254   0.001969   \n",
       "138           -0.122071    -0.116710           -0.111350   0.001486   \n",
       "139            0.073140     0.084300            0.095460   0.003094   \n",
       "140            0.063547     0.071799            0.080051   0.002288   \n",
       "141            0.038645     0.047688            0.056731   0.002507   \n",
       "142           -0.006590    -0.000211            0.006169   0.001769   \n",
       "143           -0.085954    -0.081104           -0.076254   0.001345   \n",
       "144            0.187035     0.196777            0.206519   0.002701   \n",
       "145            0.162102     0.173269            0.184436   0.003096   \n",
       "146            0.112395     0.120059            0.127724   0.002125   \n",
       "147           -0.005455    -0.001566            0.002324   0.001078   \n",
       "\n",
       "     Lower Bound NO SEX INF  Mean NO SEX INF  Upper Bound NO SEX INF  \\\n",
       "0                  0.000406         0.002265                0.004125   \n",
       "1                  0.087717         0.090891                0.094065   \n",
       "2                  0.130164         0.133451                0.136738   \n",
       "3                  0.139889         0.143022                0.146155   \n",
       "4                 -0.091742        -0.088745               -0.085749   \n",
       "5                 -0.002442         0.000753                0.003947   \n",
       "6                  0.044187         0.047858                0.051529   \n",
       "7                  0.057076         0.060793                0.064509   \n",
       "8                  0.039869         0.043589                0.047309   \n",
       "9                 -0.140698        -0.137225               -0.133753   \n",
       "10                -0.053197        -0.049582               -0.045967   \n",
       "11                -0.007054        -0.003535               -0.000015   \n",
       "12                 0.007586         0.011753                0.015920   \n",
       "13                -0.008176        -0.004084                0.000009   \n",
       "14                -0.050837        -0.047015               -0.043192   \n",
       "15                -0.148334        -0.145004               -0.141673   \n",
       "16                -0.065478        -0.061676               -0.057875   \n",
       "17                -0.021442        -0.017858               -0.014275   \n",
       "18                -0.010727        -0.006709               -0.002691   \n",
       "19                -0.023484        -0.019716               -0.015949   \n",
       "20                -0.068532        -0.064865               -0.061199   \n",
       "21                -0.149431        -0.146058               -0.142685   \n",
       "22                -0.048340        -0.044298               -0.040256   \n",
       "23                -0.004077        -0.000171                0.003736   \n",
       "24                 0.009746         0.013236                0.016727   \n",
       "25                -0.005437        -0.001884                0.001670   \n",
       "26                -0.049138        -0.045927               -0.042716   \n",
       "27                -0.135087        -0.132287               -0.129488   \n",
       "28                 0.041527         0.044520                0.047513   \n",
       "29                 0.057473         0.061040                0.064607   \n",
       "..                      ...              ...                     ...   \n",
       "118                0.077743         0.087416                0.097089   \n",
       "119                0.086303         0.096232                0.106160   \n",
       "120               -0.125908        -0.119778               -0.113648   \n",
       "121               -0.049068        -0.041146               -0.033225   \n",
       "122               -0.009636        -0.000100                0.009437   \n",
       "123                0.005425         0.014394                0.023363   \n",
       "124                0.001367         0.010142                0.018916   \n",
       "125               -0.021484        -0.014366               -0.007247   \n",
       "126               -0.126580        -0.120212               -0.113845   \n",
       "127               -0.051644        -0.043581               -0.035518   \n",
       "128               -0.021848        -0.012052               -0.002255   \n",
       "129               -0.012124        -0.003805                0.004514   \n",
       "130               -0.027954        -0.020247               -0.012540   \n",
       "131               -0.059989        -0.052999               -0.046009   \n",
       "132               -0.122616        -0.116859               -0.111102   \n",
       "133               -0.017975        -0.008446                0.001083   \n",
       "134                0.008190         0.018228                0.028265   \n",
       "135                0.006442         0.013610                0.020777   \n",
       "136               -0.015839        -0.007478                0.000884   \n",
       "137               -0.051494        -0.044459               -0.037424   \n",
       "138               -0.121233        -0.115761               -0.110288   \n",
       "139                0.091802         0.101669                0.111536   \n",
       "140                0.070489         0.079125                0.087762   \n",
       "141                0.040525         0.049164                0.057802   \n",
       "142               -0.006332        -0.000174                0.005984   \n",
       "143               -0.085101        -0.080295               -0.075488   \n",
       "144                0.222472         0.235571                0.248670   \n",
       "145                0.183869         0.194626                0.205383   \n",
       "146                0.116592         0.123740                0.130887   \n",
       "147               -0.004071        -0.000233                0.003604   \n",
       "\n",
       "     SD NO SEX INF  \n",
       "0         0.000516  \n",
       "1         0.000880  \n",
       "2         0.000911  \n",
       "3         0.000869  \n",
       "4         0.000831  \n",
       "5         0.000886  \n",
       "6         0.001018  \n",
       "7         0.001030  \n",
       "8         0.001031  \n",
       "9         0.000963  \n",
       "10        0.001002  \n",
       "11        0.000976  \n",
       "12        0.001155  \n",
       "13        0.001135  \n",
       "14        0.001060  \n",
       "15        0.000923  \n",
       "16        0.001054  \n",
       "17        0.000993  \n",
       "18        0.001114  \n",
       "19        0.001044  \n",
       "20        0.001016  \n",
       "21        0.000935  \n",
       "22        0.001121  \n",
       "23        0.001083  \n",
       "24        0.000968  \n",
       "25        0.000985  \n",
       "26        0.000890  \n",
       "27        0.000776  \n",
       "28        0.000830  \n",
       "29        0.000989  \n",
       "..             ...  \n",
       "118       0.002682  \n",
       "119       0.002752  \n",
       "120       0.001700  \n",
       "121       0.002196  \n",
       "122       0.002644  \n",
       "123       0.002486  \n",
       "124       0.002433  \n",
       "125       0.001973  \n",
       "126       0.001765  \n",
       "127       0.002235  \n",
       "128       0.002716  \n",
       "129       0.002306  \n",
       "130       0.002137  \n",
       "131       0.001938  \n",
       "132       0.001596  \n",
       "133       0.002642  \n",
       "134       0.002783  \n",
       "135       0.001987  \n",
       "136       0.002318  \n",
       "137       0.001950  \n",
       "138       0.001517  \n",
       "139       0.002735  \n",
       "140       0.002394  \n",
       "141       0.002395  \n",
       "142       0.001707  \n",
       "143       0.001333  \n",
       "144       0.003631  \n",
       "145       0.002982  \n",
       "146       0.001981  \n",
       "147       0.001064  \n",
       "\n",
       "[148 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biasconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "for i in range(0, 148):\n",
    "    plt.plot([biasconf['Lower Bound Bias'][i],biasconf['Upper Bound Bias'][i]],[148-i,148-i], '-',linewidth=0.8,color=\"black\")\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing clean dataset with the normal one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Hypothesis 1 \n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with Probability Differnce of Men and Women = 0\" )\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_d00,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis1.png\")\n",
    "\n",
    "#Hypothesis 1 CLEAN\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with Probability Differnce of Men and Women = 0\" )\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_d00_clean,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis1_clean.png\")\n",
    "\n",
    "#Hypothesis 2\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with 50% Mens Ratio in Sample\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_50,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis2.png\")\n",
    "\n",
    "#Hypothesis 2 CLEAN\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.set(font_scale=1.5)\n",
    "plt.title(\"Bias in Samples with 50% Mens Ratio in Sample\")\n",
    "ax = sns.boxplot(x=\"Exp. Group\", y=\"Bias\",data=data_50_clean,width=0.8)\n",
    "ax.set(ylim=(-0.4,0.4))\n",
    "ax\n",
    "\n",
    "ax.figure.savefig(\"hypothesis2_clean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
